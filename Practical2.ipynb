{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "authorship_tag": "ABX9TyMTX+vrjJRYBZFrQIT4o3jS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/opheliaming/deep-learning-v2-pytorch/blob/master/Practical2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPt4DeuUpIlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from random import shuffle\n",
        "import re\n",
        "\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import lxml.etree"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSVz1ivQ3Gy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isfile('ted_en-20160408.zip'):\n",
        "    urllib.request.urlretrieve(\"https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&filename=ted_en-20160408.zip\", filename=\"ted_en-20160408.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orCthl843Phm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
        "    doc = lxml.etree.parse(z.open('ted_en-20160408.xml', 'r'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kphpKA0HIt6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label(x):\n",
        "  y = []\n",
        "  for word in [\"Technology\", \"Entertainment\", \"Design\"]:\n",
        "    y.append(word[0] if word.lower() in x.lower() else 'o')\n",
        "  return y "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "885cfrmWF5Fs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keyword = doc.xpath('//keywords/text()')\n",
        "keyword_label = [label(x) for x in keyword]\n",
        "keyword_label = [''.join(x) for x in keyword_label]\n",
        "input_text = doc.xpath('//content/text()')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhHKjRoyGiu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentense_ted_tokens = []\n",
        "for sent_str in input_text:\n",
        "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", sent_str.lower()).split()\n",
        "    sentense_ted_tokens.append(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7F8cqw4hiyh",
        "colab_type": "code",
        "outputId": "ca7f5ca4-c573-49d0-fb34-324f053b0cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "embed_model = Word2Vec(min_count=1)\n",
        "embed_model.build_vocab(sentense_ted_tokens)\n",
        "embed_model.train(sentense_ted_tokens,total_examples=embed_model.corpus_count,epochs=embed_model.epochs)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16322935, 22462445)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB-x_5HgiG42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "words_top_vec = [np.mean(embed_model.wv[x], axis=0) for x in sentense_ted_tokens]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gesox-GsT1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_labels = set(keyword_label)\n",
        "label_lookup = dict(zip(sorted(unique_labels), range(len(unique_labels))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRdZFq9Gtx5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keyword_label_index = [label_lookup[label] for label in keyword_label]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O9hfv2qYsJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set  = list(zip(words_top_vec[:1585], keyword_label_index[:1585]))\n",
        "validation_set = list(zip(words_top_vec[1585:(1585+250)], keyword_label_index[1585:(1585+250)]))\n",
        "test_set = list(zip(words_top_vec[(1585+250):(1585+500)], keyword_label_index[(1585+250):(1585+500)]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwjeISS2OtKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF8gVnu0JqoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "validationloader = torch.utils.data.DataLoader(validation_set, batch_size=64, shuffle=True)\n",
        "testloader =  torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9v2YD-3V5OP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(100,50)\n",
        "        self.layer2 = nn.Linear(50,8)\n",
        "    \n",
        "    def forward(self, x):     \n",
        "        x = x.view(x.shape[0], -1) \n",
        "        x = nn.Tanh()(self.layer1(x))\n",
        "        x = F.log_softmax(self.layer2(x),dim=1)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH4gaKFYXSi9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Classifier()\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q8bjEEGXpjK",
        "colab_type": "code",
        "outputId": "a7fc731c-0d35-4947-f5c8-c547a17aa9c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 1000\n",
        "steps = 0\n",
        "train_losses, test_losses = [], []\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for word_vec, labels in trainloader:\n",
        "        optimizer.zero_grad()\n",
        "        log_ps = model(word_vec)\n",
        "        loss = criterion(log_ps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()       \n",
        "        running_loss += loss.item()\n",
        "\n",
        "    validation_loss = 0\n",
        "    accuracy = 0\n",
        "    # Turn off gradients for validation, saves memory and computations\n",
        "    with torch.no_grad():\n",
        "        for word_vec, labels in validationloader:\n",
        "            log_ps = model(word_vec)\n",
        "            validation_loss += criterion(log_ps, labels)\n",
        "            ps = torch.exp(log_ps)\n",
        "            top_p, top_class = ps.topk(1, dim=1)\n",
        "            equals = top_class == labels.view(*top_class.shape)\n",
        "            accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "      #train_losses.append(running_loss/len(trainloader))\n",
        "      #validation_loss.append(validation_loss/len(validationloader))\n",
        "\n",
        "    print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "        \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
        "        \"Test Loss: {:.3f}.. \".format(validation_loss/len(validationloader)),\n",
        "        \"Test Accuracy: {:.3f}\".format(accuracy/len(validationloader)))\n",
        "    train_losses.append(running_loss/len(trainloader))\n",
        "    test_losses.append(validation_loss/len(validationloader))\n",
        " #    else:\n",
        "#        print(f\"Training loss: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/1000..  Training Loss: 0.026..  Test Loss: 5.231..  Test Accuracy: 0.412\n",
            "Epoch: 2/1000..  Training Loss: 0.027..  Test Loss: 5.419..  Test Accuracy: 0.413\n",
            "Epoch: 3/1000..  Training Loss: 0.035..  Test Loss: 5.370..  Test Accuracy: 0.407\n",
            "Epoch: 4/1000..  Training Loss: 0.026..  Test Loss: 5.386..  Test Accuracy: 0.409\n",
            "Epoch: 5/1000..  Training Loss: 0.031..  Test Loss: 5.628..  Test Accuracy: 0.409\n",
            "Epoch: 6/1000..  Training Loss: 0.031..  Test Loss: 5.447..  Test Accuracy: 0.404\n",
            "Epoch: 7/1000..  Training Loss: 0.028..  Test Loss: 5.303..  Test Accuracy: 0.409\n",
            "Epoch: 8/1000..  Training Loss: 0.024..  Test Loss: 5.255..  Test Accuracy: 0.414\n",
            "Epoch: 9/1000..  Training Loss: 0.025..  Test Loss: 5.178..  Test Accuracy: 0.423\n",
            "Epoch: 10/1000..  Training Loss: 0.023..  Test Loss: 5.420..  Test Accuracy: 0.412\n",
            "Epoch: 11/1000..  Training Loss: 0.024..  Test Loss: 5.245..  Test Accuracy: 0.416\n",
            "Epoch: 12/1000..  Training Loss: 0.023..  Test Loss: 5.477..  Test Accuracy: 0.412\n",
            "Epoch: 13/1000..  Training Loss: 0.024..  Test Loss: 5.374..  Test Accuracy: 0.396\n",
            "Epoch: 14/1000..  Training Loss: 0.023..  Test Loss: 5.333..  Test Accuracy: 0.413\n",
            "Epoch: 15/1000..  Training Loss: 0.022..  Test Loss: 5.348..  Test Accuracy: 0.412\n",
            "Epoch: 16/1000..  Training Loss: 0.023..  Test Loss: 5.368..  Test Accuracy: 0.415\n",
            "Epoch: 17/1000..  Training Loss: 0.022..  Test Loss: 5.260..  Test Accuracy: 0.417\n",
            "Epoch: 18/1000..  Training Loss: 0.023..  Test Loss: 5.434..  Test Accuracy: 0.409\n",
            "Epoch: 19/1000..  Training Loss: 0.022..  Test Loss: 5.330..  Test Accuracy: 0.418\n",
            "Epoch: 20/1000..  Training Loss: 0.026..  Test Loss: 5.391..  Test Accuracy: 0.409\n",
            "Epoch: 21/1000..  Training Loss: 0.023..  Test Loss: 5.614..  Test Accuracy: 0.415\n",
            "Epoch: 22/1000..  Training Loss: 0.024..  Test Loss: 5.535..  Test Accuracy: 0.412\n",
            "Epoch: 23/1000..  Training Loss: 0.033..  Test Loss: 5.467..  Test Accuracy: 0.423\n",
            "Epoch: 24/1000..  Training Loss: 0.030..  Test Loss: 5.628..  Test Accuracy: 0.407\n",
            "Epoch: 25/1000..  Training Loss: 0.031..  Test Loss: 5.530..  Test Accuracy: 0.411\n",
            "Epoch: 26/1000..  Training Loss: 0.028..  Test Loss: 5.286..  Test Accuracy: 0.419\n",
            "Epoch: 27/1000..  Training Loss: 0.026..  Test Loss: 5.325..  Test Accuracy: 0.407\n",
            "Epoch: 28/1000..  Training Loss: 0.022..  Test Loss: 5.461..  Test Accuracy: 0.412\n",
            "Epoch: 29/1000..  Training Loss: 0.023..  Test Loss: 5.479..  Test Accuracy: 0.412\n",
            "Epoch: 30/1000..  Training Loss: 0.024..  Test Loss: 5.345..  Test Accuracy: 0.404\n",
            "Epoch: 31/1000..  Training Loss: 0.024..  Test Loss: 5.428..  Test Accuracy: 0.415\n",
            "Epoch: 32/1000..  Training Loss: 0.021..  Test Loss: 5.590..  Test Accuracy: 0.413\n",
            "Epoch: 33/1000..  Training Loss: 0.020..  Test Loss: 5.560..  Test Accuracy: 0.412\n",
            "Epoch: 34/1000..  Training Loss: 0.021..  Test Loss: 5.386..  Test Accuracy: 0.418\n",
            "Epoch: 35/1000..  Training Loss: 0.023..  Test Loss: 5.496..  Test Accuracy: 0.411\n",
            "Epoch: 36/1000..  Training Loss: 0.026..  Test Loss: 5.912..  Test Accuracy: 0.407\n",
            "Epoch: 37/1000..  Training Loss: 0.038..  Test Loss: 5.690..  Test Accuracy: 0.407\n",
            "Epoch: 38/1000..  Training Loss: 0.034..  Test Loss: 5.443..  Test Accuracy: 0.425\n",
            "Epoch: 39/1000..  Training Loss: 0.022..  Test Loss: 5.463..  Test Accuracy: 0.414\n",
            "Epoch: 40/1000..  Training Loss: 0.022..  Test Loss: 5.479..  Test Accuracy: 0.404\n",
            "Epoch: 41/1000..  Training Loss: 0.024..  Test Loss: 5.667..  Test Accuracy: 0.403\n",
            "Epoch: 42/1000..  Training Loss: 0.021..  Test Loss: 5.571..  Test Accuracy: 0.407\n",
            "Epoch: 43/1000..  Training Loss: 0.019..  Test Loss: 5.583..  Test Accuracy: 0.416\n",
            "Epoch: 44/1000..  Training Loss: 0.019..  Test Loss: 5.528..  Test Accuracy: 0.408\n",
            "Epoch: 45/1000..  Training Loss: 0.019..  Test Loss: 5.786..  Test Accuracy: 0.406\n",
            "Epoch: 46/1000..  Training Loss: 0.019..  Test Loss: 5.681..  Test Accuracy: 0.404\n",
            "Epoch: 47/1000..  Training Loss: 0.020..  Test Loss: 5.464..  Test Accuracy: 0.416\n",
            "Epoch: 48/1000..  Training Loss: 0.019..  Test Loss: 5.646..  Test Accuracy: 0.406\n",
            "Epoch: 49/1000..  Training Loss: 0.019..  Test Loss: 5.504..  Test Accuracy: 0.410\n",
            "Epoch: 50/1000..  Training Loss: 0.020..  Test Loss: 5.421..  Test Accuracy: 0.409\n",
            "Epoch: 51/1000..  Training Loss: 0.023..  Test Loss: 5.582..  Test Accuracy: 0.414\n",
            "Epoch: 52/1000..  Training Loss: 0.021..  Test Loss: 5.526..  Test Accuracy: 0.406\n",
            "Epoch: 53/1000..  Training Loss: 0.018..  Test Loss: 5.568..  Test Accuracy: 0.414\n",
            "Epoch: 54/1000..  Training Loss: 0.018..  Test Loss: 5.668..  Test Accuracy: 0.405\n",
            "Epoch: 55/1000..  Training Loss: 0.018..  Test Loss: 5.627..  Test Accuracy: 0.415\n",
            "Epoch: 56/1000..  Training Loss: 0.018..  Test Loss: 5.747..  Test Accuracy: 0.419\n",
            "Epoch: 57/1000..  Training Loss: 0.018..  Test Loss: 5.555..  Test Accuracy: 0.400\n",
            "Epoch: 58/1000..  Training Loss: 0.018..  Test Loss: 5.677..  Test Accuracy: 0.406\n",
            "Epoch: 59/1000..  Training Loss: 0.020..  Test Loss: 5.789..  Test Accuracy: 0.415\n",
            "Epoch: 60/1000..  Training Loss: 0.018..  Test Loss: 5.640..  Test Accuracy: 0.413\n",
            "Epoch: 61/1000..  Training Loss: 0.017..  Test Loss: 5.660..  Test Accuracy: 0.413\n",
            "Epoch: 62/1000..  Training Loss: 0.020..  Test Loss: 5.756..  Test Accuracy: 0.416\n",
            "Epoch: 63/1000..  Training Loss: 0.019..  Test Loss: 5.679..  Test Accuracy: 0.404\n",
            "Epoch: 64/1000..  Training Loss: 0.018..  Test Loss: 5.499..  Test Accuracy: 0.418\n",
            "Epoch: 65/1000..  Training Loss: 0.021..  Test Loss: 5.548..  Test Accuracy: 0.421\n",
            "Epoch: 66/1000..  Training Loss: 0.025..  Test Loss: 5.355..  Test Accuracy: 0.405\n",
            "Epoch: 67/1000..  Training Loss: 0.023..  Test Loss: 5.704..  Test Accuracy: 0.412\n",
            "Epoch: 68/1000..  Training Loss: 0.017..  Test Loss: 5.707..  Test Accuracy: 0.413\n",
            "Epoch: 69/1000..  Training Loss: 0.017..  Test Loss: 5.645..  Test Accuracy: 0.409\n",
            "Epoch: 70/1000..  Training Loss: 0.016..  Test Loss: 5.688..  Test Accuracy: 0.416\n",
            "Epoch: 71/1000..  Training Loss: 0.016..  Test Loss: 5.658..  Test Accuracy: 0.413\n",
            "Epoch: 72/1000..  Training Loss: 0.016..  Test Loss: 5.713..  Test Accuracy: 0.407\n",
            "Epoch: 73/1000..  Training Loss: 0.017..  Test Loss: 5.596..  Test Accuracy: 0.392\n",
            "Epoch: 74/1000..  Training Loss: 0.017..  Test Loss: 5.762..  Test Accuracy: 0.418\n",
            "Epoch: 75/1000..  Training Loss: 0.017..  Test Loss: 5.727..  Test Accuracy: 0.419\n",
            "Epoch: 76/1000..  Training Loss: 0.017..  Test Loss: 5.755..  Test Accuracy: 0.409\n",
            "Epoch: 77/1000..  Training Loss: 0.016..  Test Loss: 5.678..  Test Accuracy: 0.404\n",
            "Epoch: 78/1000..  Training Loss: 0.017..  Test Loss: 5.800..  Test Accuracy: 0.405\n",
            "Epoch: 79/1000..  Training Loss: 0.021..  Test Loss: 5.897..  Test Accuracy: 0.405\n",
            "Epoch: 80/1000..  Training Loss: 0.040..  Test Loss: 5.489..  Test Accuracy: 0.428\n",
            "Epoch: 81/1000..  Training Loss: 0.037..  Test Loss: 6.194..  Test Accuracy: 0.441\n",
            "Epoch: 82/1000..  Training Loss: 0.059..  Test Loss: 5.692..  Test Accuracy: 0.412\n",
            "Epoch: 83/1000..  Training Loss: 0.052..  Test Loss: 5.682..  Test Accuracy: 0.404\n",
            "Epoch: 84/1000..  Training Loss: 0.034..  Test Loss: 5.908..  Test Accuracy: 0.419\n",
            "Epoch: 85/1000..  Training Loss: 0.022..  Test Loss: 5.779..  Test Accuracy: 0.399\n",
            "Epoch: 86/1000..  Training Loss: 0.019..  Test Loss: 5.750..  Test Accuracy: 0.414\n",
            "Epoch: 87/1000..  Training Loss: 0.015..  Test Loss: 5.999..  Test Accuracy: 0.411\n",
            "Epoch: 88/1000..  Training Loss: 0.015..  Test Loss: 5.931..  Test Accuracy: 0.403\n",
            "Epoch: 89/1000..  Training Loss: 0.014..  Test Loss: 5.828..  Test Accuracy: 0.402\n",
            "Epoch: 90/1000..  Training Loss: 0.015..  Test Loss: 5.863..  Test Accuracy: 0.401\n",
            "Epoch: 91/1000..  Training Loss: 0.015..  Test Loss: 5.937..  Test Accuracy: 0.408\n",
            "Epoch: 92/1000..  Training Loss: 0.015..  Test Loss: 5.598..  Test Accuracy: 0.413\n",
            "Epoch: 93/1000..  Training Loss: 0.017..  Test Loss: 6.040..  Test Accuracy: 0.398\n",
            "Epoch: 94/1000..  Training Loss: 0.016..  Test Loss: 5.873..  Test Accuracy: 0.402\n",
            "Epoch: 95/1000..  Training Loss: 0.014..  Test Loss: 5.689..  Test Accuracy: 0.416\n",
            "Epoch: 96/1000..  Training Loss: 0.014..  Test Loss: 5.728..  Test Accuracy: 0.414\n",
            "Epoch: 97/1000..  Training Loss: 0.014..  Test Loss: 5.887..  Test Accuracy: 0.409\n",
            "Epoch: 98/1000..  Training Loss: 0.016..  Test Loss: 5.699..  Test Accuracy: 0.408\n",
            "Epoch: 99/1000..  Training Loss: 0.016..  Test Loss: 5.842..  Test Accuracy: 0.402\n",
            "Epoch: 100/1000..  Training Loss: 0.015..  Test Loss: 5.851..  Test Accuracy: 0.407\n",
            "Epoch: 101/1000..  Training Loss: 0.013..  Test Loss: 5.866..  Test Accuracy: 0.403\n",
            "Epoch: 102/1000..  Training Loss: 0.014..  Test Loss: 5.757..  Test Accuracy: 0.415\n",
            "Epoch: 103/1000..  Training Loss: 0.016..  Test Loss: 5.981..  Test Accuracy: 0.409\n",
            "Epoch: 104/1000..  Training Loss: 0.017..  Test Loss: 5.824..  Test Accuracy: 0.415\n",
            "Epoch: 105/1000..  Training Loss: 0.015..  Test Loss: 5.917..  Test Accuracy: 0.406\n",
            "Epoch: 106/1000..  Training Loss: 0.014..  Test Loss: 5.851..  Test Accuracy: 0.406\n",
            "Epoch: 107/1000..  Training Loss: 0.014..  Test Loss: 5.777..  Test Accuracy: 0.414\n",
            "Epoch: 108/1000..  Training Loss: 0.013..  Test Loss: 5.941..  Test Accuracy: 0.412\n",
            "Epoch: 109/1000..  Training Loss: 0.013..  Test Loss: 5.958..  Test Accuracy: 0.406\n",
            "Epoch: 110/1000..  Training Loss: 0.013..  Test Loss: 5.908..  Test Accuracy: 0.411\n",
            "Epoch: 111/1000..  Training Loss: 0.014..  Test Loss: 5.967..  Test Accuracy: 0.411\n",
            "Epoch: 112/1000..  Training Loss: 0.014..  Test Loss: 5.912..  Test Accuracy: 0.412\n",
            "Epoch: 113/1000..  Training Loss: 0.013..  Test Loss: 5.772..  Test Accuracy: 0.405\n",
            "Epoch: 114/1000..  Training Loss: 0.014..  Test Loss: 6.027..  Test Accuracy: 0.406\n",
            "Epoch: 115/1000..  Training Loss: 0.014..  Test Loss: 6.049..  Test Accuracy: 0.409\n",
            "Epoch: 116/1000..  Training Loss: 0.013..  Test Loss: 5.922..  Test Accuracy: 0.415\n",
            "Epoch: 117/1000..  Training Loss: 0.013..  Test Loss: 5.911..  Test Accuracy: 0.408\n",
            "Epoch: 118/1000..  Training Loss: 0.013..  Test Loss: 6.001..  Test Accuracy: 0.409\n",
            "Epoch: 119/1000..  Training Loss: 0.013..  Test Loss: 6.040..  Test Accuracy: 0.404\n",
            "Epoch: 120/1000..  Training Loss: 0.014..  Test Loss: 6.018..  Test Accuracy: 0.413\n",
            "Epoch: 121/1000..  Training Loss: 0.013..  Test Loss: 5.921..  Test Accuracy: 0.405\n",
            "Epoch: 122/1000..  Training Loss: 0.013..  Test Loss: 5.916..  Test Accuracy: 0.420\n",
            "Epoch: 123/1000..  Training Loss: 0.013..  Test Loss: 6.003..  Test Accuracy: 0.412\n",
            "Epoch: 124/1000..  Training Loss: 0.013..  Test Loss: 5.969..  Test Accuracy: 0.412\n",
            "Epoch: 125/1000..  Training Loss: 0.013..  Test Loss: 6.024..  Test Accuracy: 0.417\n",
            "Epoch: 126/1000..  Training Loss: 0.016..  Test Loss: 6.015..  Test Accuracy: 0.405\n",
            "Epoch: 127/1000..  Training Loss: 0.015..  Test Loss: 5.957..  Test Accuracy: 0.416\n",
            "Epoch: 128/1000..  Training Loss: 0.012..  Test Loss: 6.081..  Test Accuracy: 0.406\n",
            "Epoch: 129/1000..  Training Loss: 0.012..  Test Loss: 6.048..  Test Accuracy: 0.401\n",
            "Epoch: 130/1000..  Training Loss: 0.012..  Test Loss: 6.073..  Test Accuracy: 0.414\n",
            "Epoch: 131/1000..  Training Loss: 0.012..  Test Loss: 5.946..  Test Accuracy: 0.418\n",
            "Epoch: 132/1000..  Training Loss: 0.012..  Test Loss: 6.057..  Test Accuracy: 0.408\n",
            "Epoch: 133/1000..  Training Loss: 0.013..  Test Loss: 5.887..  Test Accuracy: 0.410\n",
            "Epoch: 134/1000..  Training Loss: 0.012..  Test Loss: 6.006..  Test Accuracy: 0.416\n",
            "Epoch: 135/1000..  Training Loss: 0.012..  Test Loss: 6.031..  Test Accuracy: 0.417\n",
            "Epoch: 136/1000..  Training Loss: 0.012..  Test Loss: 5.925..  Test Accuracy: 0.417\n",
            "Epoch: 137/1000..  Training Loss: 0.013..  Test Loss: 6.052..  Test Accuracy: 0.421\n",
            "Epoch: 138/1000..  Training Loss: 0.012..  Test Loss: 6.074..  Test Accuracy: 0.408\n",
            "Epoch: 139/1000..  Training Loss: 0.012..  Test Loss: 6.030..  Test Accuracy: 0.409\n",
            "Epoch: 140/1000..  Training Loss: 0.012..  Test Loss: 6.125..  Test Accuracy: 0.416\n",
            "Epoch: 141/1000..  Training Loss: 0.012..  Test Loss: 6.044..  Test Accuracy: 0.417\n",
            "Epoch: 142/1000..  Training Loss: 0.013..  Test Loss: 6.276..  Test Accuracy: 0.412\n",
            "Epoch: 143/1000..  Training Loss: 0.015..  Test Loss: 5.949..  Test Accuracy: 0.407\n",
            "Epoch: 144/1000..  Training Loss: 0.013..  Test Loss: 6.149..  Test Accuracy: 0.410\n",
            "Epoch: 145/1000..  Training Loss: 0.012..  Test Loss: 6.082..  Test Accuracy: 0.407\n",
            "Epoch: 146/1000..  Training Loss: 0.012..  Test Loss: 6.170..  Test Accuracy: 0.412\n",
            "Epoch: 147/1000..  Training Loss: 0.013..  Test Loss: 6.014..  Test Accuracy: 0.408\n",
            "Epoch: 148/1000..  Training Loss: 0.015..  Test Loss: 5.985..  Test Accuracy: 0.405\n",
            "Epoch: 149/1000..  Training Loss: 0.017..  Test Loss: 5.598..  Test Accuracy: 0.420\n",
            "Epoch: 150/1000..  Training Loss: 0.068..  Test Loss: 6.331..  Test Accuracy: 0.410\n",
            "Epoch: 151/1000..  Training Loss: 0.099..  Test Loss: 6.006..  Test Accuracy: 0.419\n",
            "Epoch: 152/1000..  Training Loss: 0.033..  Test Loss: 5.886..  Test Accuracy: 0.407\n",
            "Epoch: 153/1000..  Training Loss: 0.024..  Test Loss: 6.351..  Test Accuracy: 0.425\n",
            "Epoch: 154/1000..  Training Loss: 0.014..  Test Loss: 5.989..  Test Accuracy: 0.405\n",
            "Epoch: 155/1000..  Training Loss: 0.011..  Test Loss: 6.106..  Test Accuracy: 0.412\n",
            "Epoch: 156/1000..  Training Loss: 0.011..  Test Loss: 6.165..  Test Accuracy: 0.409\n",
            "Epoch: 157/1000..  Training Loss: 0.011..  Test Loss: 6.077..  Test Accuracy: 0.408\n",
            "Epoch: 158/1000..  Training Loss: 0.011..  Test Loss: 6.159..  Test Accuracy: 0.404\n",
            "Epoch: 159/1000..  Training Loss: 0.010..  Test Loss: 6.229..  Test Accuracy: 0.414\n",
            "Epoch: 160/1000..  Training Loss: 0.010..  Test Loss: 6.188..  Test Accuracy: 0.415\n",
            "Epoch: 161/1000..  Training Loss: 0.010..  Test Loss: 6.221..  Test Accuracy: 0.405\n",
            "Epoch: 162/1000..  Training Loss: 0.010..  Test Loss: 6.184..  Test Accuracy: 0.415\n",
            "Epoch: 163/1000..  Training Loss: 0.010..  Test Loss: 6.183..  Test Accuracy: 0.417\n",
            "Epoch: 164/1000..  Training Loss: 0.010..  Test Loss: 6.242..  Test Accuracy: 0.413\n",
            "Epoch: 165/1000..  Training Loss: 0.010..  Test Loss: 6.114..  Test Accuracy: 0.412\n",
            "Epoch: 166/1000..  Training Loss: 0.010..  Test Loss: 6.235..  Test Accuracy: 0.418\n",
            "Epoch: 167/1000..  Training Loss: 0.010..  Test Loss: 6.143..  Test Accuracy: 0.416\n",
            "Epoch: 168/1000..  Training Loss: 0.011..  Test Loss: 6.118..  Test Accuracy: 0.418\n",
            "Epoch: 169/1000..  Training Loss: 0.011..  Test Loss: 6.197..  Test Accuracy: 0.407\n",
            "Epoch: 170/1000..  Training Loss: 0.010..  Test Loss: 6.207..  Test Accuracy: 0.417\n",
            "Epoch: 171/1000..  Training Loss: 0.010..  Test Loss: 6.229..  Test Accuracy: 0.421\n",
            "Epoch: 172/1000..  Training Loss: 0.010..  Test Loss: 6.207..  Test Accuracy: 0.415\n",
            "Epoch: 173/1000..  Training Loss: 0.010..  Test Loss: 6.174..  Test Accuracy: 0.408\n",
            "Epoch: 174/1000..  Training Loss: 0.010..  Test Loss: 6.198..  Test Accuracy: 0.416\n",
            "Epoch: 175/1000..  Training Loss: 0.010..  Test Loss: 6.174..  Test Accuracy: 0.414\n",
            "Epoch: 176/1000..  Training Loss: 0.010..  Test Loss: 6.226..  Test Accuracy: 0.419\n",
            "Epoch: 177/1000..  Training Loss: 0.010..  Test Loss: 6.220..  Test Accuracy: 0.412\n",
            "Epoch: 178/1000..  Training Loss: 0.010..  Test Loss: 6.076..  Test Accuracy: 0.420\n",
            "Epoch: 179/1000..  Training Loss: 0.010..  Test Loss: 6.300..  Test Accuracy: 0.408\n",
            "Epoch: 180/1000..  Training Loss: 0.010..  Test Loss: 6.189..  Test Accuracy: 0.416\n",
            "Epoch: 181/1000..  Training Loss: 0.010..  Test Loss: 6.246..  Test Accuracy: 0.414\n",
            "Epoch: 182/1000..  Training Loss: 0.010..  Test Loss: 6.384..  Test Accuracy: 0.412\n",
            "Epoch: 183/1000..  Training Loss: 0.010..  Test Loss: 6.229..  Test Accuracy: 0.419\n",
            "Epoch: 184/1000..  Training Loss: 0.010..  Test Loss: 6.293..  Test Accuracy: 0.414\n",
            "Epoch: 185/1000..  Training Loss: 0.010..  Test Loss: 6.199..  Test Accuracy: 0.415\n",
            "Epoch: 186/1000..  Training Loss: 0.010..  Test Loss: 6.223..  Test Accuracy: 0.419\n",
            "Epoch: 187/1000..  Training Loss: 0.010..  Test Loss: 6.250..  Test Accuracy: 0.409\n",
            "Epoch: 188/1000..  Training Loss: 0.010..  Test Loss: 6.170..  Test Accuracy: 0.410\n",
            "Epoch: 189/1000..  Training Loss: 0.010..  Test Loss: 6.260..  Test Accuracy: 0.409\n",
            "Epoch: 190/1000..  Training Loss: 0.009..  Test Loss: 6.310..  Test Accuracy: 0.420\n",
            "Epoch: 191/1000..  Training Loss: 0.010..  Test Loss: 6.234..  Test Accuracy: 0.417\n",
            "Epoch: 192/1000..  Training Loss: 0.009..  Test Loss: 6.356..  Test Accuracy: 0.411\n",
            "Epoch: 193/1000..  Training Loss: 0.010..  Test Loss: 6.200..  Test Accuracy: 0.407\n",
            "Epoch: 194/1000..  Training Loss: 0.010..  Test Loss: 6.154..  Test Accuracy: 0.413\n",
            "Epoch: 195/1000..  Training Loss: 0.010..  Test Loss: 6.268..  Test Accuracy: 0.406\n",
            "Epoch: 196/1000..  Training Loss: 0.010..  Test Loss: 6.322..  Test Accuracy: 0.417\n",
            "Epoch: 197/1000..  Training Loss: 0.009..  Test Loss: 6.313..  Test Accuracy: 0.417\n",
            "Epoch: 198/1000..  Training Loss: 0.009..  Test Loss: 6.340..  Test Accuracy: 0.416\n",
            "Epoch: 199/1000..  Training Loss: 0.009..  Test Loss: 6.438..  Test Accuracy: 0.414\n",
            "Epoch: 200/1000..  Training Loss: 0.010..  Test Loss: 6.367..  Test Accuracy: 0.413\n",
            "Epoch: 201/1000..  Training Loss: 0.009..  Test Loss: 6.346..  Test Accuracy: 0.418\n",
            "Epoch: 202/1000..  Training Loss: 0.010..  Test Loss: 6.235..  Test Accuracy: 0.413\n",
            "Epoch: 203/1000..  Training Loss: 0.009..  Test Loss: 6.266..  Test Accuracy: 0.406\n",
            "Epoch: 204/1000..  Training Loss: 0.010..  Test Loss: 6.376..  Test Accuracy: 0.413\n",
            "Epoch: 205/1000..  Training Loss: 0.010..  Test Loss: 6.413..  Test Accuracy: 0.418\n",
            "Epoch: 206/1000..  Training Loss: 0.009..  Test Loss: 6.418..  Test Accuracy: 0.413\n",
            "Epoch: 207/1000..  Training Loss: 0.009..  Test Loss: 6.279..  Test Accuracy: 0.416\n",
            "Epoch: 208/1000..  Training Loss: 0.010..  Test Loss: 6.184..  Test Accuracy: 0.412\n",
            "Epoch: 209/1000..  Training Loss: 0.010..  Test Loss: 6.369..  Test Accuracy: 0.417\n",
            "Epoch: 210/1000..  Training Loss: 0.009..  Test Loss: 6.364..  Test Accuracy: 0.415\n",
            "Epoch: 211/1000..  Training Loss: 0.009..  Test Loss: 6.313..  Test Accuracy: 0.424\n",
            "Epoch: 212/1000..  Training Loss: 0.009..  Test Loss: 6.430..  Test Accuracy: 0.422\n",
            "Epoch: 213/1000..  Training Loss: 0.009..  Test Loss: 6.331..  Test Accuracy: 0.424\n",
            "Epoch: 214/1000..  Training Loss: 0.009..  Test Loss: 6.414..  Test Accuracy: 0.420\n",
            "Epoch: 215/1000..  Training Loss: 0.009..  Test Loss: 6.455..  Test Accuracy: 0.406\n",
            "Epoch: 216/1000..  Training Loss: 0.009..  Test Loss: 6.297..  Test Accuracy: 0.409\n",
            "Epoch: 217/1000..  Training Loss: 0.009..  Test Loss: 6.441..  Test Accuracy: 0.416\n",
            "Epoch: 218/1000..  Training Loss: 0.009..  Test Loss: 6.317..  Test Accuracy: 0.418\n",
            "Epoch: 219/1000..  Training Loss: 0.009..  Test Loss: 6.412..  Test Accuracy: 0.416\n",
            "Epoch: 220/1000..  Training Loss: 0.009..  Test Loss: 6.436..  Test Accuracy: 0.415\n",
            "Epoch: 221/1000..  Training Loss: 0.008..  Test Loss: 6.345..  Test Accuracy: 0.419\n",
            "Epoch: 222/1000..  Training Loss: 0.009..  Test Loss: 6.410..  Test Accuracy: 0.418\n",
            "Epoch: 223/1000..  Training Loss: 0.009..  Test Loss: 6.436..  Test Accuracy: 0.412\n",
            "Epoch: 224/1000..  Training Loss: 0.009..  Test Loss: 6.314..  Test Accuracy: 0.417\n",
            "Epoch: 225/1000..  Training Loss: 0.009..  Test Loss: 6.530..  Test Accuracy: 0.412\n",
            "Epoch: 226/1000..  Training Loss: 0.009..  Test Loss: 6.475..  Test Accuracy: 0.422\n",
            "Epoch: 227/1000..  Training Loss: 0.009..  Test Loss: 6.442..  Test Accuracy: 0.417\n",
            "Epoch: 228/1000..  Training Loss: 0.009..  Test Loss: 6.465..  Test Accuracy: 0.415\n",
            "Epoch: 229/1000..  Training Loss: 0.009..  Test Loss: 6.455..  Test Accuracy: 0.414\n",
            "Epoch: 230/1000..  Training Loss: 0.009..  Test Loss: 6.406..  Test Accuracy: 0.417\n",
            "Epoch: 231/1000..  Training Loss: 0.009..  Test Loss: 6.425..  Test Accuracy: 0.416\n",
            "Epoch: 232/1000..  Training Loss: 0.008..  Test Loss: 6.476..  Test Accuracy: 0.428\n",
            "Epoch: 233/1000..  Training Loss: 0.009..  Test Loss: 6.482..  Test Accuracy: 0.416\n",
            "Epoch: 234/1000..  Training Loss: 0.009..  Test Loss: 6.393..  Test Accuracy: 0.417\n",
            "Epoch: 235/1000..  Training Loss: 0.009..  Test Loss: 6.475..  Test Accuracy: 0.418\n",
            "Epoch: 236/1000..  Training Loss: 0.009..  Test Loss: 6.577..  Test Accuracy: 0.416\n",
            "Epoch: 237/1000..  Training Loss: 0.009..  Test Loss: 6.432..  Test Accuracy: 0.412\n",
            "Epoch: 238/1000..  Training Loss: 0.009..  Test Loss: 6.442..  Test Accuracy: 0.413\n",
            "Epoch: 239/1000..  Training Loss: 0.008..  Test Loss: 6.582..  Test Accuracy: 0.415\n",
            "Epoch: 240/1000..  Training Loss: 0.008..  Test Loss: 6.510..  Test Accuracy: 0.421\n",
            "Epoch: 241/1000..  Training Loss: 0.008..  Test Loss: 6.467..  Test Accuracy: 0.404\n",
            "Epoch: 242/1000..  Training Loss: 0.009..  Test Loss: 6.631..  Test Accuracy: 0.417\n",
            "Epoch: 243/1000..  Training Loss: 0.008..  Test Loss: 6.581..  Test Accuracy: 0.415\n",
            "Epoch: 244/1000..  Training Loss: 0.008..  Test Loss: 6.456..  Test Accuracy: 0.415\n",
            "Epoch: 245/1000..  Training Loss: 0.008..  Test Loss: 6.510..  Test Accuracy: 0.417\n",
            "Epoch: 246/1000..  Training Loss: 0.009..  Test Loss: 6.555..  Test Accuracy: 0.421\n",
            "Epoch: 247/1000..  Training Loss: 0.009..  Test Loss: 6.350..  Test Accuracy: 0.412\n",
            "Epoch: 248/1000..  Training Loss: 0.011..  Test Loss: 6.437..  Test Accuracy: 0.408\n",
            "Epoch: 249/1000..  Training Loss: 0.027..  Test Loss: 6.691..  Test Accuracy: 0.412\n",
            "Epoch: 250/1000..  Training Loss: 0.049..  Test Loss: 6.329..  Test Accuracy: 0.407\n",
            "Epoch: 251/1000..  Training Loss: 0.050..  Test Loss: 6.489..  Test Accuracy: 0.415\n",
            "Epoch: 252/1000..  Training Loss: 0.142..  Test Loss: 7.567..  Test Accuracy: 0.429\n",
            "Epoch: 253/1000..  Training Loss: 0.135..  Test Loss: 6.846..  Test Accuracy: 0.412\n",
            "Epoch: 254/1000..  Training Loss: 0.069..  Test Loss: 7.272..  Test Accuracy: 0.413\n",
            "Epoch: 255/1000..  Training Loss: 0.037..  Test Loss: 6.375..  Test Accuracy: 0.412\n",
            "Epoch: 256/1000..  Training Loss: 0.012..  Test Loss: 6.766..  Test Accuracy: 0.429\n",
            "Epoch: 257/1000..  Training Loss: 0.008..  Test Loss: 6.538..  Test Accuracy: 0.416\n",
            "Epoch: 258/1000..  Training Loss: 0.008..  Test Loss: 6.605..  Test Accuracy: 0.420\n",
            "Epoch: 259/1000..  Training Loss: 0.008..  Test Loss: 6.590..  Test Accuracy: 0.420\n",
            "Epoch: 260/1000..  Training Loss: 0.008..  Test Loss: 6.643..  Test Accuracy: 0.420\n",
            "Epoch: 261/1000..  Training Loss: 0.008..  Test Loss: 6.616..  Test Accuracy: 0.421\n",
            "Epoch: 262/1000..  Training Loss: 0.007..  Test Loss: 6.614..  Test Accuracy: 0.417\n",
            "Epoch: 263/1000..  Training Loss: 0.008..  Test Loss: 6.618..  Test Accuracy: 0.422\n",
            "Epoch: 264/1000..  Training Loss: 0.008..  Test Loss: 6.607..  Test Accuracy: 0.420\n",
            "Epoch: 265/1000..  Training Loss: 0.007..  Test Loss: 6.659..  Test Accuracy: 0.417\n",
            "Epoch: 266/1000..  Training Loss: 0.007..  Test Loss: 6.618..  Test Accuracy: 0.421\n",
            "Epoch: 267/1000..  Training Loss: 0.007..  Test Loss: 6.613..  Test Accuracy: 0.415\n",
            "Epoch: 268/1000..  Training Loss: 0.007..  Test Loss: 6.686..  Test Accuracy: 0.423\n",
            "Epoch: 269/1000..  Training Loss: 0.007..  Test Loss: 6.628..  Test Accuracy: 0.418\n",
            "Epoch: 270/1000..  Training Loss: 0.007..  Test Loss: 6.545..  Test Accuracy: 0.420\n",
            "Epoch: 271/1000..  Training Loss: 0.007..  Test Loss: 6.564..  Test Accuracy: 0.414\n",
            "Epoch: 272/1000..  Training Loss: 0.008..  Test Loss: 6.675..  Test Accuracy: 0.413\n",
            "Epoch: 273/1000..  Training Loss: 0.008..  Test Loss: 6.649..  Test Accuracy: 0.419\n",
            "Epoch: 274/1000..  Training Loss: 0.007..  Test Loss: 6.679..  Test Accuracy: 0.422\n",
            "Epoch: 275/1000..  Training Loss: 0.007..  Test Loss: 6.659..  Test Accuracy: 0.410\n",
            "Epoch: 276/1000..  Training Loss: 0.007..  Test Loss: 6.559..  Test Accuracy: 0.412\n",
            "Epoch: 277/1000..  Training Loss: 0.007..  Test Loss: 6.589..  Test Accuracy: 0.410\n",
            "Epoch: 278/1000..  Training Loss: 0.007..  Test Loss: 6.564..  Test Accuracy: 0.426\n",
            "Epoch: 279/1000..  Training Loss: 0.007..  Test Loss: 6.671..  Test Accuracy: 0.428\n",
            "Epoch: 280/1000..  Training Loss: 0.007..  Test Loss: 6.669..  Test Accuracy: 0.423\n",
            "Epoch: 281/1000..  Training Loss: 0.007..  Test Loss: 6.643..  Test Accuracy: 0.423\n",
            "Epoch: 282/1000..  Training Loss: 0.007..  Test Loss: 6.599..  Test Accuracy: 0.423\n",
            "Epoch: 283/1000..  Training Loss: 0.007..  Test Loss: 6.585..  Test Accuracy: 0.416\n",
            "Epoch: 284/1000..  Training Loss: 0.007..  Test Loss: 6.586..  Test Accuracy: 0.426\n",
            "Epoch: 285/1000..  Training Loss: 0.007..  Test Loss: 6.604..  Test Accuracy: 0.419\n",
            "Epoch: 286/1000..  Training Loss: 0.007..  Test Loss: 6.700..  Test Accuracy: 0.427\n",
            "Epoch: 287/1000..  Training Loss: 0.007..  Test Loss: 6.592..  Test Accuracy: 0.418\n",
            "Epoch: 288/1000..  Training Loss: 0.007..  Test Loss: 6.646..  Test Accuracy: 0.425\n",
            "Epoch: 289/1000..  Training Loss: 0.007..  Test Loss: 6.696..  Test Accuracy: 0.416\n",
            "Epoch: 290/1000..  Training Loss: 0.007..  Test Loss: 6.563..  Test Accuracy: 0.420\n",
            "Epoch: 291/1000..  Training Loss: 0.007..  Test Loss: 6.631..  Test Accuracy: 0.426\n",
            "Epoch: 292/1000..  Training Loss: 0.008..  Test Loss: 6.639..  Test Accuracy: 0.418\n",
            "Epoch: 293/1000..  Training Loss: 0.007..  Test Loss: 6.647..  Test Accuracy: 0.423\n",
            "Epoch: 294/1000..  Training Loss: 0.008..  Test Loss: 6.682..  Test Accuracy: 0.408\n",
            "Epoch: 295/1000..  Training Loss: 0.007..  Test Loss: 6.642..  Test Accuracy: 0.419\n",
            "Epoch: 296/1000..  Training Loss: 0.007..  Test Loss: 6.632..  Test Accuracy: 0.421\n",
            "Epoch: 297/1000..  Training Loss: 0.007..  Test Loss: 6.574..  Test Accuracy: 0.419\n",
            "Epoch: 298/1000..  Training Loss: 0.007..  Test Loss: 6.670..  Test Accuracy: 0.419\n",
            "Epoch: 299/1000..  Training Loss: 0.007..  Test Loss: 6.615..  Test Accuracy: 0.418\n",
            "Epoch: 300/1000..  Training Loss: 0.007..  Test Loss: 6.654..  Test Accuracy: 0.412\n",
            "Epoch: 301/1000..  Training Loss: 0.007..  Test Loss: 6.705..  Test Accuracy: 0.425\n",
            "Epoch: 302/1000..  Training Loss: 0.007..  Test Loss: 6.638..  Test Accuracy: 0.423\n",
            "Epoch: 303/1000..  Training Loss: 0.007..  Test Loss: 6.651..  Test Accuracy: 0.421\n",
            "Epoch: 304/1000..  Training Loss: 0.007..  Test Loss: 6.654..  Test Accuracy: 0.418\n",
            "Epoch: 305/1000..  Training Loss: 0.007..  Test Loss: 6.660..  Test Accuracy: 0.425\n",
            "Epoch: 306/1000..  Training Loss: 0.007..  Test Loss: 6.621..  Test Accuracy: 0.420\n",
            "Epoch: 307/1000..  Training Loss: 0.007..  Test Loss: 6.720..  Test Accuracy: 0.419\n",
            "Epoch: 308/1000..  Training Loss: 0.007..  Test Loss: 6.702..  Test Accuracy: 0.414\n",
            "Epoch: 309/1000..  Training Loss: 0.007..  Test Loss: 6.736..  Test Accuracy: 0.423\n",
            "Epoch: 310/1000..  Training Loss: 0.007..  Test Loss: 6.636..  Test Accuracy: 0.425\n",
            "Epoch: 311/1000..  Training Loss: 0.007..  Test Loss: 6.782..  Test Accuracy: 0.414\n",
            "Epoch: 312/1000..  Training Loss: 0.007..  Test Loss: 6.654..  Test Accuracy: 0.421\n",
            "Epoch: 313/1000..  Training Loss: 0.007..  Test Loss: 6.677..  Test Accuracy: 0.415\n",
            "Epoch: 314/1000..  Training Loss: 0.007..  Test Loss: 6.705..  Test Accuracy: 0.421\n",
            "Epoch: 315/1000..  Training Loss: 0.007..  Test Loss: 6.680..  Test Accuracy: 0.420\n",
            "Epoch: 316/1000..  Training Loss: 0.007..  Test Loss: 6.720..  Test Accuracy: 0.416\n",
            "Epoch: 317/1000..  Training Loss: 0.007..  Test Loss: 6.706..  Test Accuracy: 0.412\n",
            "Epoch: 318/1000..  Training Loss: 0.007..  Test Loss: 6.787..  Test Accuracy: 0.418\n",
            "Epoch: 319/1000..  Training Loss: 0.007..  Test Loss: 6.625..  Test Accuracy: 0.419\n",
            "Epoch: 320/1000..  Training Loss: 0.007..  Test Loss: 6.747..  Test Accuracy: 0.422\n",
            "Epoch: 321/1000..  Training Loss: 0.007..  Test Loss: 6.717..  Test Accuracy: 0.415\n",
            "Epoch: 322/1000..  Training Loss: 0.007..  Test Loss: 6.707..  Test Accuracy: 0.419\n",
            "Epoch: 323/1000..  Training Loss: 0.007..  Test Loss: 6.664..  Test Accuracy: 0.419\n",
            "Epoch: 324/1000..  Training Loss: 0.007..  Test Loss: 6.761..  Test Accuracy: 0.421\n",
            "Epoch: 325/1000..  Training Loss: 0.007..  Test Loss: 6.721..  Test Accuracy: 0.419\n",
            "Epoch: 326/1000..  Training Loss: 0.007..  Test Loss: 6.726..  Test Accuracy: 0.415\n",
            "Epoch: 327/1000..  Training Loss: 0.007..  Test Loss: 6.746..  Test Accuracy: 0.420\n",
            "Epoch: 328/1000..  Training Loss: 0.007..  Test Loss: 6.769..  Test Accuracy: 0.419\n",
            "Epoch: 329/1000..  Training Loss: 0.007..  Test Loss: 6.703..  Test Accuracy: 0.419\n",
            "Epoch: 330/1000..  Training Loss: 0.007..  Test Loss: 6.646..  Test Accuracy: 0.421\n",
            "Epoch: 331/1000..  Training Loss: 0.007..  Test Loss: 6.739..  Test Accuracy: 0.420\n",
            "Epoch: 332/1000..  Training Loss: 0.006..  Test Loss: 6.722..  Test Accuracy: 0.419\n",
            "Epoch: 333/1000..  Training Loss: 0.006..  Test Loss: 6.757..  Test Accuracy: 0.420\n",
            "Epoch: 334/1000..  Training Loss: 0.007..  Test Loss: 6.755..  Test Accuracy: 0.420\n",
            "Epoch: 335/1000..  Training Loss: 0.007..  Test Loss: 6.816..  Test Accuracy: 0.422\n",
            "Epoch: 336/1000..  Training Loss: 0.007..  Test Loss: 6.757..  Test Accuracy: 0.421\n",
            "Epoch: 337/1000..  Training Loss: 0.007..  Test Loss: 6.699..  Test Accuracy: 0.408\n",
            "Epoch: 338/1000..  Training Loss: 0.007..  Test Loss: 6.722..  Test Accuracy: 0.423\n",
            "Epoch: 339/1000..  Training Loss: 0.007..  Test Loss: 6.729..  Test Accuracy: 0.417\n",
            "Epoch: 340/1000..  Training Loss: 0.006..  Test Loss: 6.756..  Test Accuracy: 0.419\n",
            "Epoch: 341/1000..  Training Loss: 0.007..  Test Loss: 6.694..  Test Accuracy: 0.422\n",
            "Epoch: 342/1000..  Training Loss: 0.007..  Test Loss: 6.725..  Test Accuracy: 0.417\n",
            "Epoch: 343/1000..  Training Loss: 0.007..  Test Loss: 6.798..  Test Accuracy: 0.427\n",
            "Epoch: 344/1000..  Training Loss: 0.006..  Test Loss: 6.733..  Test Accuracy: 0.418\n",
            "Epoch: 345/1000..  Training Loss: 0.007..  Test Loss: 6.733..  Test Accuracy: 0.419\n",
            "Epoch: 346/1000..  Training Loss: 0.007..  Test Loss: 6.793..  Test Accuracy: 0.422\n",
            "Epoch: 347/1000..  Training Loss: 0.006..  Test Loss: 6.861..  Test Accuracy: 0.423\n",
            "Epoch: 348/1000..  Training Loss: 0.006..  Test Loss: 6.839..  Test Accuracy: 0.412\n",
            "Epoch: 349/1000..  Training Loss: 0.006..  Test Loss: 6.806..  Test Accuracy: 0.423\n",
            "Epoch: 350/1000..  Training Loss: 0.007..  Test Loss: 6.759..  Test Accuracy: 0.423\n",
            "Epoch: 351/1000..  Training Loss: 0.006..  Test Loss: 6.796..  Test Accuracy: 0.419\n",
            "Epoch: 352/1000..  Training Loss: 0.007..  Test Loss: 6.736..  Test Accuracy: 0.421\n",
            "Epoch: 353/1000..  Training Loss: 0.006..  Test Loss: 6.905..  Test Accuracy: 0.423\n",
            "Epoch: 354/1000..  Training Loss: 0.007..  Test Loss: 6.781..  Test Accuracy: 0.425\n",
            "Epoch: 355/1000..  Training Loss: 0.007..  Test Loss: 6.801..  Test Accuracy: 0.416\n",
            "Epoch: 356/1000..  Training Loss: 0.007..  Test Loss: 6.788..  Test Accuracy: 0.412\n",
            "Epoch: 357/1000..  Training Loss: 0.006..  Test Loss: 6.719..  Test Accuracy: 0.423\n",
            "Epoch: 358/1000..  Training Loss: 0.006..  Test Loss: 6.784..  Test Accuracy: 0.421\n",
            "Epoch: 359/1000..  Training Loss: 0.006..  Test Loss: 6.805..  Test Accuracy: 0.419\n",
            "Epoch: 360/1000..  Training Loss: 0.007..  Test Loss: 6.788..  Test Accuracy: 0.427\n",
            "Epoch: 361/1000..  Training Loss: 0.007..  Test Loss: 6.795..  Test Accuracy: 0.420\n",
            "Epoch: 362/1000..  Training Loss: 0.007..  Test Loss: 6.854..  Test Accuracy: 0.425\n",
            "Epoch: 363/1000..  Training Loss: 0.007..  Test Loss: 6.708..  Test Accuracy: 0.419\n",
            "Epoch: 364/1000..  Training Loss: 0.006..  Test Loss: 6.809..  Test Accuracy: 0.419\n",
            "Epoch: 365/1000..  Training Loss: 0.006..  Test Loss: 6.842..  Test Accuracy: 0.414\n",
            "Epoch: 366/1000..  Training Loss: 0.006..  Test Loss: 6.932..  Test Accuracy: 0.416\n",
            "Epoch: 367/1000..  Training Loss: 0.007..  Test Loss: 6.865..  Test Accuracy: 0.403\n",
            "Epoch: 368/1000..  Training Loss: 0.006..  Test Loss: 6.655..  Test Accuracy: 0.426\n",
            "Epoch: 369/1000..  Training Loss: 0.007..  Test Loss: 6.953..  Test Accuracy: 0.420\n",
            "Epoch: 370/1000..  Training Loss: 0.006..  Test Loss: 6.858..  Test Accuracy: 0.409\n",
            "Epoch: 371/1000..  Training Loss: 0.006..  Test Loss: 6.893..  Test Accuracy: 0.417\n",
            "Epoch: 372/1000..  Training Loss: 0.006..  Test Loss: 6.854..  Test Accuracy: 0.421\n",
            "Epoch: 373/1000..  Training Loss: 0.006..  Test Loss: 6.881..  Test Accuracy: 0.410\n",
            "Epoch: 374/1000..  Training Loss: 0.006..  Test Loss: 6.867..  Test Accuracy: 0.419\n",
            "Epoch: 375/1000..  Training Loss: 0.006..  Test Loss: 6.826..  Test Accuracy: 0.416\n",
            "Epoch: 376/1000..  Training Loss: 0.006..  Test Loss: 6.835..  Test Accuracy: 0.419\n",
            "Epoch: 377/1000..  Training Loss: 0.006..  Test Loss: 6.884..  Test Accuracy: 0.412\n",
            "Epoch: 378/1000..  Training Loss: 0.006..  Test Loss: 6.950..  Test Accuracy: 0.417\n",
            "Epoch: 379/1000..  Training Loss: 0.006..  Test Loss: 6.878..  Test Accuracy: 0.416\n",
            "Epoch: 380/1000..  Training Loss: 0.006..  Test Loss: 6.791..  Test Accuracy: 0.416\n",
            "Epoch: 381/1000..  Training Loss: 0.006..  Test Loss: 6.857..  Test Accuracy: 0.413\n",
            "Epoch: 382/1000..  Training Loss: 0.006..  Test Loss: 6.953..  Test Accuracy: 0.414\n",
            "Epoch: 383/1000..  Training Loss: 0.006..  Test Loss: 7.043..  Test Accuracy: 0.417\n",
            "Epoch: 384/1000..  Training Loss: 0.006..  Test Loss: 6.772..  Test Accuracy: 0.409\n",
            "Epoch: 385/1000..  Training Loss: 0.006..  Test Loss: 7.006..  Test Accuracy: 0.415\n",
            "Epoch: 386/1000..  Training Loss: 0.006..  Test Loss: 7.000..  Test Accuracy: 0.412\n",
            "Epoch: 387/1000..  Training Loss: 0.006..  Test Loss: 6.985..  Test Accuracy: 0.412\n",
            "Epoch: 388/1000..  Training Loss: 0.006..  Test Loss: 6.919..  Test Accuracy: 0.419\n",
            "Epoch: 389/1000..  Training Loss: 0.006..  Test Loss: 6.924..  Test Accuracy: 0.423\n",
            "Epoch: 390/1000..  Training Loss: 0.006..  Test Loss: 6.911..  Test Accuracy: 0.416\n",
            "Epoch: 391/1000..  Training Loss: 0.006..  Test Loss: 7.005..  Test Accuracy: 0.415\n",
            "Epoch: 392/1000..  Training Loss: 0.006..  Test Loss: 6.807..  Test Accuracy: 0.414\n",
            "Epoch: 393/1000..  Training Loss: 0.007..  Test Loss: 7.242..  Test Accuracy: 0.421\n",
            "Epoch: 394/1000..  Training Loss: 0.007..  Test Loss: 7.051..  Test Accuracy: 0.403\n",
            "Epoch: 395/1000..  Training Loss: 0.010..  Test Loss: 6.800..  Test Accuracy: 0.426\n",
            "Epoch: 396/1000..  Training Loss: 0.067..  Test Loss: 8.234..  Test Accuracy: 0.412\n",
            "Epoch: 397/1000..  Training Loss: 0.269..  Test Loss: 6.615..  Test Accuracy: 0.416\n",
            "Epoch: 398/1000..  Training Loss: 0.066..  Test Loss: 6.982..  Test Accuracy: 0.399\n",
            "Epoch: 399/1000..  Training Loss: 0.022..  Test Loss: 6.829..  Test Accuracy: 0.407\n",
            "Epoch: 400/1000..  Training Loss: 0.009..  Test Loss: 6.986..  Test Accuracy: 0.409\n",
            "Epoch: 401/1000..  Training Loss: 0.007..  Test Loss: 7.094..  Test Accuracy: 0.405\n",
            "Epoch: 402/1000..  Training Loss: 0.006..  Test Loss: 6.989..  Test Accuracy: 0.409\n",
            "Epoch: 403/1000..  Training Loss: 0.006..  Test Loss: 6.926..  Test Accuracy: 0.402\n",
            "Epoch: 404/1000..  Training Loss: 0.006..  Test Loss: 6.926..  Test Accuracy: 0.407\n",
            "Epoch: 405/1000..  Training Loss: 0.006..  Test Loss: 6.874..  Test Accuracy: 0.409\n",
            "Epoch: 406/1000..  Training Loss: 0.006..  Test Loss: 6.934..  Test Accuracy: 0.409\n",
            "Epoch: 407/1000..  Training Loss: 0.006..  Test Loss: 6.991..  Test Accuracy: 0.402\n",
            "Epoch: 408/1000..  Training Loss: 0.006..  Test Loss: 6.931..  Test Accuracy: 0.409\n",
            "Epoch: 409/1000..  Training Loss: 0.006..  Test Loss: 6.982..  Test Accuracy: 0.408\n",
            "Epoch: 410/1000..  Training Loss: 0.006..  Test Loss: 6.847..  Test Accuracy: 0.411\n",
            "Epoch: 411/1000..  Training Loss: 0.006..  Test Loss: 6.977..  Test Accuracy: 0.408\n",
            "Epoch: 412/1000..  Training Loss: 0.006..  Test Loss: 6.930..  Test Accuracy: 0.412\n",
            "Epoch: 413/1000..  Training Loss: 0.006..  Test Loss: 7.060..  Test Accuracy: 0.408\n",
            "Epoch: 414/1000..  Training Loss: 0.006..  Test Loss: 6.896..  Test Accuracy: 0.413\n",
            "Epoch: 415/1000..  Training Loss: 0.006..  Test Loss: 6.919..  Test Accuracy: 0.408\n",
            "Epoch: 416/1000..  Training Loss: 0.006..  Test Loss: 6.961..  Test Accuracy: 0.408\n",
            "Epoch: 417/1000..  Training Loss: 0.006..  Test Loss: 7.016..  Test Accuracy: 0.409\n",
            "Epoch: 418/1000..  Training Loss: 0.006..  Test Loss: 7.006..  Test Accuracy: 0.409\n",
            "Epoch: 419/1000..  Training Loss: 0.006..  Test Loss: 6.892..  Test Accuracy: 0.413\n",
            "Epoch: 420/1000..  Training Loss: 0.006..  Test Loss: 6.895..  Test Accuracy: 0.410\n",
            "Epoch: 421/1000..  Training Loss: 0.006..  Test Loss: 7.004..  Test Accuracy: 0.413\n",
            "Epoch: 422/1000..  Training Loss: 0.006..  Test Loss: 7.024..  Test Accuracy: 0.412\n",
            "Epoch: 423/1000..  Training Loss: 0.006..  Test Loss: 6.935..  Test Accuracy: 0.414\n",
            "Epoch: 424/1000..  Training Loss: 0.006..  Test Loss: 6.911..  Test Accuracy: 0.412\n",
            "Epoch: 425/1000..  Training Loss: 0.006..  Test Loss: 6.956..  Test Accuracy: 0.412\n",
            "Epoch: 426/1000..  Training Loss: 0.006..  Test Loss: 6.897..  Test Accuracy: 0.414\n",
            "Epoch: 427/1000..  Training Loss: 0.006..  Test Loss: 6.916..  Test Accuracy: 0.413\n",
            "Epoch: 428/1000..  Training Loss: 0.006..  Test Loss: 6.995..  Test Accuracy: 0.410\n",
            "Epoch: 429/1000..  Training Loss: 0.005..  Test Loss: 6.980..  Test Accuracy: 0.417\n",
            "Epoch: 430/1000..  Training Loss: 0.006..  Test Loss: 7.039..  Test Accuracy: 0.416\n",
            "Epoch: 431/1000..  Training Loss: 0.005..  Test Loss: 7.026..  Test Accuracy: 0.412\n",
            "Epoch: 432/1000..  Training Loss: 0.005..  Test Loss: 7.016..  Test Accuracy: 0.415\n",
            "Epoch: 433/1000..  Training Loss: 0.005..  Test Loss: 7.032..  Test Accuracy: 0.413\n",
            "Epoch: 434/1000..  Training Loss: 0.006..  Test Loss: 7.013..  Test Accuracy: 0.415\n",
            "Epoch: 435/1000..  Training Loss: 0.006..  Test Loss: 7.038..  Test Accuracy: 0.414\n",
            "Epoch: 436/1000..  Training Loss: 0.006..  Test Loss: 7.003..  Test Accuracy: 0.414\n",
            "Epoch: 437/1000..  Training Loss: 0.005..  Test Loss: 7.002..  Test Accuracy: 0.415\n",
            "Epoch: 438/1000..  Training Loss: 0.005..  Test Loss: 6.975..  Test Accuracy: 0.420\n",
            "Epoch: 439/1000..  Training Loss: 0.006..  Test Loss: 7.027..  Test Accuracy: 0.416\n",
            "Epoch: 440/1000..  Training Loss: 0.006..  Test Loss: 6.984..  Test Accuracy: 0.420\n",
            "Epoch: 441/1000..  Training Loss: 0.006..  Test Loss: 6.960..  Test Accuracy: 0.417\n",
            "Epoch: 442/1000..  Training Loss: 0.006..  Test Loss: 6.995..  Test Accuracy: 0.418\n",
            "Epoch: 443/1000..  Training Loss: 0.006..  Test Loss: 7.054..  Test Accuracy: 0.416\n",
            "Epoch: 444/1000..  Training Loss: 0.005..  Test Loss: 7.093..  Test Accuracy: 0.419\n",
            "Epoch: 445/1000..  Training Loss: 0.005..  Test Loss: 6.930..  Test Accuracy: 0.421\n",
            "Epoch: 446/1000..  Training Loss: 0.005..  Test Loss: 7.007..  Test Accuracy: 0.425\n",
            "Epoch: 447/1000..  Training Loss: 0.005..  Test Loss: 7.079..  Test Accuracy: 0.418\n",
            "Epoch: 448/1000..  Training Loss: 0.006..  Test Loss: 7.057..  Test Accuracy: 0.415\n",
            "Epoch: 449/1000..  Training Loss: 0.005..  Test Loss: 6.974..  Test Accuracy: 0.414\n",
            "Epoch: 450/1000..  Training Loss: 0.006..  Test Loss: 7.069..  Test Accuracy: 0.416\n",
            "Epoch: 451/1000..  Training Loss: 0.005..  Test Loss: 7.015..  Test Accuracy: 0.421\n",
            "Epoch: 452/1000..  Training Loss: 0.005..  Test Loss: 7.017..  Test Accuracy: 0.418\n",
            "Epoch: 453/1000..  Training Loss: 0.006..  Test Loss: 7.005..  Test Accuracy: 0.421\n",
            "Epoch: 454/1000..  Training Loss: 0.005..  Test Loss: 7.004..  Test Accuracy: 0.416\n",
            "Epoch: 455/1000..  Training Loss: 0.005..  Test Loss: 6.977..  Test Accuracy: 0.425\n",
            "Epoch: 456/1000..  Training Loss: 0.006..  Test Loss: 7.019..  Test Accuracy: 0.420\n",
            "Epoch: 457/1000..  Training Loss: 0.005..  Test Loss: 7.025..  Test Accuracy: 0.421\n",
            "Epoch: 458/1000..  Training Loss: 0.005..  Test Loss: 6.981..  Test Accuracy: 0.421\n",
            "Epoch: 459/1000..  Training Loss: 0.005..  Test Loss: 7.051..  Test Accuracy: 0.420\n",
            "Epoch: 460/1000..  Training Loss: 0.005..  Test Loss: 7.018..  Test Accuracy: 0.415\n",
            "Epoch: 461/1000..  Training Loss: 0.005..  Test Loss: 7.076..  Test Accuracy: 0.419\n",
            "Epoch: 462/1000..  Training Loss: 0.006..  Test Loss: 7.062..  Test Accuracy: 0.427\n",
            "Epoch: 463/1000..  Training Loss: 0.006..  Test Loss: 6.954..  Test Accuracy: 0.426\n",
            "Epoch: 464/1000..  Training Loss: 0.006..  Test Loss: 7.160..  Test Accuracy: 0.420\n",
            "Epoch: 465/1000..  Training Loss: 0.005..  Test Loss: 6.986..  Test Accuracy: 0.418\n",
            "Epoch: 466/1000..  Training Loss: 0.005..  Test Loss: 7.003..  Test Accuracy: 0.417\n",
            "Epoch: 467/1000..  Training Loss: 0.005..  Test Loss: 7.073..  Test Accuracy: 0.419\n",
            "Epoch: 468/1000..  Training Loss: 0.005..  Test Loss: 7.075..  Test Accuracy: 0.421\n",
            "Epoch: 469/1000..  Training Loss: 0.005..  Test Loss: 7.045..  Test Accuracy: 0.420\n",
            "Epoch: 470/1000..  Training Loss: 0.005..  Test Loss: 7.092..  Test Accuracy: 0.417\n",
            "Epoch: 471/1000..  Training Loss: 0.005..  Test Loss: 6.986..  Test Accuracy: 0.421\n",
            "Epoch: 472/1000..  Training Loss: 0.005..  Test Loss: 7.069..  Test Accuracy: 0.425\n",
            "Epoch: 473/1000..  Training Loss: 0.005..  Test Loss: 7.054..  Test Accuracy: 0.416\n",
            "Epoch: 474/1000..  Training Loss: 0.005..  Test Loss: 7.056..  Test Accuracy: 0.416\n",
            "Epoch: 475/1000..  Training Loss: 0.005..  Test Loss: 7.025..  Test Accuracy: 0.410\n",
            "Epoch: 476/1000..  Training Loss: 0.005..  Test Loss: 7.105..  Test Accuracy: 0.419\n",
            "Epoch: 477/1000..  Training Loss: 0.005..  Test Loss: 6.989..  Test Accuracy: 0.421\n",
            "Epoch: 478/1000..  Training Loss: 0.005..  Test Loss: 7.110..  Test Accuracy: 0.417\n",
            "Epoch: 479/1000..  Training Loss: 0.005..  Test Loss: 7.016..  Test Accuracy: 0.420\n",
            "Epoch: 480/1000..  Training Loss: 0.005..  Test Loss: 7.069..  Test Accuracy: 0.422\n",
            "Epoch: 481/1000..  Training Loss: 0.005..  Test Loss: 7.137..  Test Accuracy: 0.418\n",
            "Epoch: 482/1000..  Training Loss: 0.005..  Test Loss: 7.026..  Test Accuracy: 0.421\n",
            "Epoch: 483/1000..  Training Loss: 0.005..  Test Loss: 7.184..  Test Accuracy: 0.416\n",
            "Epoch: 484/1000..  Training Loss: 0.005..  Test Loss: 7.089..  Test Accuracy: 0.419\n",
            "Epoch: 485/1000..  Training Loss: 0.005..  Test Loss: 7.043..  Test Accuracy: 0.423\n",
            "Epoch: 486/1000..  Training Loss: 0.005..  Test Loss: 7.102..  Test Accuracy: 0.425\n",
            "Epoch: 487/1000..  Training Loss: 0.005..  Test Loss: 7.216..  Test Accuracy: 0.422\n",
            "Epoch: 488/1000..  Training Loss: 0.005..  Test Loss: 7.105..  Test Accuracy: 0.420\n",
            "Epoch: 489/1000..  Training Loss: 0.005..  Test Loss: 7.030..  Test Accuracy: 0.417\n",
            "Epoch: 490/1000..  Training Loss: 0.005..  Test Loss: 7.028..  Test Accuracy: 0.418\n",
            "Epoch: 491/1000..  Training Loss: 0.005..  Test Loss: 7.098..  Test Accuracy: 0.421\n",
            "Epoch: 492/1000..  Training Loss: 0.005..  Test Loss: 7.131..  Test Accuracy: 0.402\n",
            "Epoch: 493/1000..  Training Loss: 0.005..  Test Loss: 7.179..  Test Accuracy: 0.419\n",
            "Epoch: 494/1000..  Training Loss: 0.005..  Test Loss: 7.165..  Test Accuracy: 0.417\n",
            "Epoch: 495/1000..  Training Loss: 0.005..  Test Loss: 6.991..  Test Accuracy: 0.419\n",
            "Epoch: 496/1000..  Training Loss: 0.005..  Test Loss: 7.111..  Test Accuracy: 0.425\n",
            "Epoch: 497/1000..  Training Loss: 0.005..  Test Loss: 7.106..  Test Accuracy: 0.419\n",
            "Epoch: 498/1000..  Training Loss: 0.005..  Test Loss: 7.115..  Test Accuracy: 0.419\n",
            "Epoch: 499/1000..  Training Loss: 0.005..  Test Loss: 7.166..  Test Accuracy: 0.420\n",
            "Epoch: 500/1000..  Training Loss: 0.005..  Test Loss: 7.139..  Test Accuracy: 0.423\n",
            "Epoch: 501/1000..  Training Loss: 0.005..  Test Loss: 7.150..  Test Accuracy: 0.424\n",
            "Epoch: 502/1000..  Training Loss: 0.005..  Test Loss: 7.043..  Test Accuracy: 0.422\n",
            "Epoch: 503/1000..  Training Loss: 0.005..  Test Loss: 7.159..  Test Accuracy: 0.414\n",
            "Epoch: 504/1000..  Training Loss: 0.005..  Test Loss: 7.127..  Test Accuracy: 0.420\n",
            "Epoch: 505/1000..  Training Loss: 0.005..  Test Loss: 7.185..  Test Accuracy: 0.419\n",
            "Epoch: 506/1000..  Training Loss: 0.005..  Test Loss: 7.116..  Test Accuracy: 0.422\n",
            "Epoch: 507/1000..  Training Loss: 0.005..  Test Loss: 7.167..  Test Accuracy: 0.418\n",
            "Epoch: 508/1000..  Training Loss: 0.005..  Test Loss: 7.075..  Test Accuracy: 0.423\n",
            "Epoch: 509/1000..  Training Loss: 0.005..  Test Loss: 7.064..  Test Accuracy: 0.416\n",
            "Epoch: 510/1000..  Training Loss: 0.006..  Test Loss: 7.096..  Test Accuracy: 0.412\n",
            "Epoch: 511/1000..  Training Loss: 0.005..  Test Loss: 7.092..  Test Accuracy: 0.419\n",
            "Epoch: 512/1000..  Training Loss: 0.005..  Test Loss: 7.139..  Test Accuracy: 0.421\n",
            "Epoch: 513/1000..  Training Loss: 0.005..  Test Loss: 7.231..  Test Accuracy: 0.412\n",
            "Epoch: 514/1000..  Training Loss: 0.005..  Test Loss: 7.203..  Test Accuracy: 0.416\n",
            "Epoch: 515/1000..  Training Loss: 0.005..  Test Loss: 7.167..  Test Accuracy: 0.426\n",
            "Epoch: 516/1000..  Training Loss: 0.005..  Test Loss: 7.136..  Test Accuracy: 0.415\n",
            "Epoch: 517/1000..  Training Loss: 0.005..  Test Loss: 6.993..  Test Accuracy: 0.418\n",
            "Epoch: 518/1000..  Training Loss: 0.005..  Test Loss: 7.206..  Test Accuracy: 0.419\n",
            "Epoch: 519/1000..  Training Loss: 0.005..  Test Loss: 7.053..  Test Accuracy: 0.414\n",
            "Epoch: 520/1000..  Training Loss: 0.005..  Test Loss: 7.268..  Test Accuracy: 0.412\n",
            "Epoch: 521/1000..  Training Loss: 0.005..  Test Loss: 7.139..  Test Accuracy: 0.417\n",
            "Epoch: 522/1000..  Training Loss: 0.005..  Test Loss: 7.169..  Test Accuracy: 0.405\n",
            "Epoch: 523/1000..  Training Loss: 0.005..  Test Loss: 7.153..  Test Accuracy: 0.421\n",
            "Epoch: 524/1000..  Training Loss: 0.006..  Test Loss: 7.248..  Test Accuracy: 0.412\n",
            "Epoch: 525/1000..  Training Loss: 0.005..  Test Loss: 7.244..  Test Accuracy: 0.416\n",
            "Epoch: 526/1000..  Training Loss: 0.005..  Test Loss: 7.140..  Test Accuracy: 0.416\n",
            "Epoch: 527/1000..  Training Loss: 0.005..  Test Loss: 7.346..  Test Accuracy: 0.414\n",
            "Epoch: 528/1000..  Training Loss: 0.005..  Test Loss: 7.138..  Test Accuracy: 0.417\n",
            "Epoch: 529/1000..  Training Loss: 0.005..  Test Loss: 7.185..  Test Accuracy: 0.416\n",
            "Epoch: 530/1000..  Training Loss: 0.005..  Test Loss: 7.088..  Test Accuracy: 0.420\n",
            "Epoch: 531/1000..  Training Loss: 0.005..  Test Loss: 7.145..  Test Accuracy: 0.420\n",
            "Epoch: 532/1000..  Training Loss: 0.005..  Test Loss: 7.343..  Test Accuracy: 0.412\n",
            "Epoch: 533/1000..  Training Loss: 0.005..  Test Loss: 7.171..  Test Accuracy: 0.418\n",
            "Epoch: 534/1000..  Training Loss: 0.005..  Test Loss: 7.302..  Test Accuracy: 0.412\n",
            "Epoch: 535/1000..  Training Loss: 0.005..  Test Loss: 7.261..  Test Accuracy: 0.417\n",
            "Epoch: 536/1000..  Training Loss: 0.005..  Test Loss: 7.230..  Test Accuracy: 0.421\n",
            "Epoch: 537/1000..  Training Loss: 0.005..  Test Loss: 7.216..  Test Accuracy: 0.423\n",
            "Epoch: 538/1000..  Training Loss: 0.005..  Test Loss: 7.150..  Test Accuracy: 0.418\n",
            "Epoch: 539/1000..  Training Loss: 0.005..  Test Loss: 7.175..  Test Accuracy: 0.420\n",
            "Epoch: 540/1000..  Training Loss: 0.005..  Test Loss: 7.231..  Test Accuracy: 0.415\n",
            "Epoch: 541/1000..  Training Loss: 0.005..  Test Loss: 7.096..  Test Accuracy: 0.420\n",
            "Epoch: 542/1000..  Training Loss: 0.005..  Test Loss: 7.262..  Test Accuracy: 0.416\n",
            "Epoch: 543/1000..  Training Loss: 0.005..  Test Loss: 7.261..  Test Accuracy: 0.418\n",
            "Epoch: 544/1000..  Training Loss: 0.005..  Test Loss: 7.151..  Test Accuracy: 0.419\n",
            "Epoch: 545/1000..  Training Loss: 0.005..  Test Loss: 7.247..  Test Accuracy: 0.415\n",
            "Epoch: 546/1000..  Training Loss: 0.005..  Test Loss: 7.184..  Test Accuracy: 0.419\n",
            "Epoch: 547/1000..  Training Loss: 0.005..  Test Loss: 7.254..  Test Accuracy: 0.412\n",
            "Epoch: 548/1000..  Training Loss: 0.005..  Test Loss: 7.273..  Test Accuracy: 0.414\n",
            "Epoch: 549/1000..  Training Loss: 0.005..  Test Loss: 7.246..  Test Accuracy: 0.415\n",
            "Epoch: 550/1000..  Training Loss: 0.005..  Test Loss: 7.356..  Test Accuracy: 0.412\n",
            "Epoch: 551/1000..  Training Loss: 0.005..  Test Loss: 7.227..  Test Accuracy: 0.423\n",
            "Epoch: 552/1000..  Training Loss: 0.005..  Test Loss: 7.212..  Test Accuracy: 0.412\n",
            "Epoch: 553/1000..  Training Loss: 0.005..  Test Loss: 7.262..  Test Accuracy: 0.415\n",
            "Epoch: 554/1000..  Training Loss: 0.005..  Test Loss: 7.232..  Test Accuracy: 0.418\n",
            "Epoch: 555/1000..  Training Loss: 0.005..  Test Loss: 7.282..  Test Accuracy: 0.420\n",
            "Epoch: 556/1000..  Training Loss: 0.005..  Test Loss: 7.313..  Test Accuracy: 0.416\n",
            "Epoch: 557/1000..  Training Loss: 0.005..  Test Loss: 7.313..  Test Accuracy: 0.419\n",
            "Epoch: 558/1000..  Training Loss: 0.004..  Test Loss: 7.207..  Test Accuracy: 0.427\n",
            "Epoch: 559/1000..  Training Loss: 0.005..  Test Loss: 7.250..  Test Accuracy: 0.421\n",
            "Epoch: 560/1000..  Training Loss: 0.005..  Test Loss: 7.369..  Test Accuracy: 0.411\n",
            "Epoch: 561/1000..  Training Loss: 0.005..  Test Loss: 7.194..  Test Accuracy: 0.415\n",
            "Epoch: 562/1000..  Training Loss: 0.005..  Test Loss: 7.339..  Test Accuracy: 0.425\n",
            "Epoch: 563/1000..  Training Loss: 0.005..  Test Loss: 7.350..  Test Accuracy: 0.418\n",
            "Epoch: 564/1000..  Training Loss: 0.005..  Test Loss: 7.347..  Test Accuracy: 0.417\n",
            "Epoch: 565/1000..  Training Loss: 0.005..  Test Loss: 7.275..  Test Accuracy: 0.421\n",
            "Epoch: 566/1000..  Training Loss: 0.005..  Test Loss: 7.288..  Test Accuracy: 0.418\n",
            "Epoch: 567/1000..  Training Loss: 0.005..  Test Loss: 7.277..  Test Accuracy: 0.414\n",
            "Epoch: 568/1000..  Training Loss: 0.005..  Test Loss: 7.296..  Test Accuracy: 0.425\n",
            "Epoch: 569/1000..  Training Loss: 0.005..  Test Loss: 7.470..  Test Accuracy: 0.408\n",
            "Epoch: 570/1000..  Training Loss: 0.005..  Test Loss: 7.439..  Test Accuracy: 0.416\n",
            "Epoch: 571/1000..  Training Loss: 0.005..  Test Loss: 7.274..  Test Accuracy: 0.425\n",
            "Epoch: 572/1000..  Training Loss: 0.005..  Test Loss: 7.497..  Test Accuracy: 0.414\n",
            "Epoch: 573/1000..  Training Loss: 0.005..  Test Loss: 7.414..  Test Accuracy: 0.416\n",
            "Epoch: 574/1000..  Training Loss: 0.005..  Test Loss: 7.299..  Test Accuracy: 0.416\n",
            "Epoch: 575/1000..  Training Loss: 0.005..  Test Loss: 7.225..  Test Accuracy: 0.416\n",
            "Epoch: 576/1000..  Training Loss: 0.005..  Test Loss: 7.323..  Test Accuracy: 0.420\n",
            "Epoch: 577/1000..  Training Loss: 0.004..  Test Loss: 7.348..  Test Accuracy: 0.419\n",
            "Epoch: 578/1000..  Training Loss: 0.005..  Test Loss: 7.422..  Test Accuracy: 0.416\n",
            "Epoch: 579/1000..  Training Loss: 0.005..  Test Loss: 7.383..  Test Accuracy: 0.416\n",
            "Epoch: 580/1000..  Training Loss: 0.005..  Test Loss: 7.285..  Test Accuracy: 0.407\n",
            "Epoch: 581/1000..  Training Loss: 0.005..  Test Loss: 7.291..  Test Accuracy: 0.416\n",
            "Epoch: 582/1000..  Training Loss: 0.004..  Test Loss: 7.603..  Test Accuracy: 0.414\n",
            "Epoch: 583/1000..  Training Loss: 0.005..  Test Loss: 7.520..  Test Accuracy: 0.414\n",
            "Epoch: 584/1000..  Training Loss: 0.005..  Test Loss: 7.511..  Test Accuracy: 0.414\n",
            "Epoch: 585/1000..  Training Loss: 0.005..  Test Loss: 7.504..  Test Accuracy: 0.410\n",
            "Epoch: 586/1000..  Training Loss: 0.005..  Test Loss: 7.359..  Test Accuracy: 0.414\n",
            "Epoch: 587/1000..  Training Loss: 0.005..  Test Loss: 7.456..  Test Accuracy: 0.407\n",
            "Epoch: 588/1000..  Training Loss: 0.005..  Test Loss: 7.382..  Test Accuracy: 0.417\n",
            "Epoch: 589/1000..  Training Loss: 0.005..  Test Loss: 7.493..  Test Accuracy: 0.420\n",
            "Epoch: 590/1000..  Training Loss: 0.005..  Test Loss: 7.562..  Test Accuracy: 0.410\n",
            "Epoch: 591/1000..  Training Loss: 0.005..  Test Loss: 7.386..  Test Accuracy: 0.414\n",
            "Epoch: 592/1000..  Training Loss: 0.005..  Test Loss: 7.424..  Test Accuracy: 0.415\n",
            "Epoch: 593/1000..  Training Loss: 0.005..  Test Loss: 7.431..  Test Accuracy: 0.407\n",
            "Epoch: 594/1000..  Training Loss: 0.005..  Test Loss: 7.313..  Test Accuracy: 0.418\n",
            "Epoch: 595/1000..  Training Loss: 0.040..  Test Loss: 7.006..  Test Accuracy: 0.406\n",
            "Epoch: 596/1000..  Training Loss: 0.763..  Test Loss: 8.795..  Test Accuracy: 0.403\n",
            "Epoch: 597/1000..  Training Loss: 0.162..  Test Loss: 7.986..  Test Accuracy: 0.414\n",
            "Epoch: 598/1000..  Training Loss: 0.036..  Test Loss: 7.030..  Test Accuracy: 0.428\n",
            "Epoch: 599/1000..  Training Loss: 0.011..  Test Loss: 7.194..  Test Accuracy: 0.424\n",
            "Epoch: 600/1000..  Training Loss: 0.007..  Test Loss: 7.413..  Test Accuracy: 0.420\n",
            "Epoch: 601/1000..  Training Loss: 0.005..  Test Loss: 7.402..  Test Accuracy: 0.429\n",
            "Epoch: 602/1000..  Training Loss: 0.005..  Test Loss: 7.361..  Test Accuracy: 0.432\n",
            "Epoch: 603/1000..  Training Loss: 0.005..  Test Loss: 7.393..  Test Accuracy: 0.433\n",
            "Epoch: 604/1000..  Training Loss: 0.005..  Test Loss: 7.345..  Test Accuracy: 0.434\n",
            "Epoch: 605/1000..  Training Loss: 0.005..  Test Loss: 7.392..  Test Accuracy: 0.431\n",
            "Epoch: 606/1000..  Training Loss: 0.005..  Test Loss: 7.412..  Test Accuracy: 0.432\n",
            "Epoch: 607/1000..  Training Loss: 0.005..  Test Loss: 7.387..  Test Accuracy: 0.431\n",
            "Epoch: 608/1000..  Training Loss: 0.005..  Test Loss: 7.381..  Test Accuracy: 0.433\n",
            "Epoch: 609/1000..  Training Loss: 0.005..  Test Loss: 7.360..  Test Accuracy: 0.433\n",
            "Epoch: 610/1000..  Training Loss: 0.005..  Test Loss: 7.384..  Test Accuracy: 0.432\n",
            "Epoch: 611/1000..  Training Loss: 0.005..  Test Loss: 7.383..  Test Accuracy: 0.433\n",
            "Epoch: 612/1000..  Training Loss: 0.005..  Test Loss: 7.395..  Test Accuracy: 0.433\n",
            "Epoch: 613/1000..  Training Loss: 0.005..  Test Loss: 7.391..  Test Accuracy: 0.434\n",
            "Epoch: 614/1000..  Training Loss: 0.005..  Test Loss: 7.431..  Test Accuracy: 0.429\n",
            "Epoch: 615/1000..  Training Loss: 0.005..  Test Loss: 7.416..  Test Accuracy: 0.432\n",
            "Epoch: 616/1000..  Training Loss: 0.005..  Test Loss: 7.452..  Test Accuracy: 0.432\n",
            "Epoch: 617/1000..  Training Loss: 0.005..  Test Loss: 7.386..  Test Accuracy: 0.434\n",
            "Epoch: 618/1000..  Training Loss: 0.004..  Test Loss: 7.412..  Test Accuracy: 0.427\n",
            "Epoch: 619/1000..  Training Loss: 0.005..  Test Loss: 7.375..  Test Accuracy: 0.428\n",
            "Epoch: 620/1000..  Training Loss: 0.004..  Test Loss: 7.406..  Test Accuracy: 0.434\n",
            "Epoch: 621/1000..  Training Loss: 0.005..  Test Loss: 7.395..  Test Accuracy: 0.429\n",
            "Epoch: 622/1000..  Training Loss: 0.004..  Test Loss: 7.397..  Test Accuracy: 0.428\n",
            "Epoch: 623/1000..  Training Loss: 0.004..  Test Loss: 7.445..  Test Accuracy: 0.423\n",
            "Epoch: 624/1000..  Training Loss: 0.005..  Test Loss: 7.410..  Test Accuracy: 0.434\n",
            "Epoch: 625/1000..  Training Loss: 0.005..  Test Loss: 7.384..  Test Accuracy: 0.427\n",
            "Epoch: 626/1000..  Training Loss: 0.004..  Test Loss: 7.441..  Test Accuracy: 0.424\n",
            "Epoch: 627/1000..  Training Loss: 0.004..  Test Loss: 7.453..  Test Accuracy: 0.426\n",
            "Epoch: 628/1000..  Training Loss: 0.004..  Test Loss: 7.450..  Test Accuracy: 0.421\n",
            "Epoch: 629/1000..  Training Loss: 0.004..  Test Loss: 7.386..  Test Accuracy: 0.425\n",
            "Epoch: 630/1000..  Training Loss: 0.004..  Test Loss: 7.421..  Test Accuracy: 0.423\n",
            "Epoch: 631/1000..  Training Loss: 0.004..  Test Loss: 7.435..  Test Accuracy: 0.427\n",
            "Epoch: 632/1000..  Training Loss: 0.005..  Test Loss: 7.438..  Test Accuracy: 0.422\n",
            "Epoch: 633/1000..  Training Loss: 0.005..  Test Loss: 7.426..  Test Accuracy: 0.429\n",
            "Epoch: 634/1000..  Training Loss: 0.004..  Test Loss: 7.455..  Test Accuracy: 0.428\n",
            "Epoch: 635/1000..  Training Loss: 0.004..  Test Loss: 7.431..  Test Accuracy: 0.425\n",
            "Epoch: 636/1000..  Training Loss: 0.004..  Test Loss: 7.466..  Test Accuracy: 0.428\n",
            "Epoch: 637/1000..  Training Loss: 0.004..  Test Loss: 7.430..  Test Accuracy: 0.418\n",
            "Epoch: 638/1000..  Training Loss: 0.004..  Test Loss: 7.415..  Test Accuracy: 0.421\n",
            "Epoch: 639/1000..  Training Loss: 0.005..  Test Loss: 7.481..  Test Accuracy: 0.425\n",
            "Epoch: 640/1000..  Training Loss: 0.004..  Test Loss: 7.425..  Test Accuracy: 0.426\n",
            "Epoch: 641/1000..  Training Loss: 0.004..  Test Loss: 7.439..  Test Accuracy: 0.423\n",
            "Epoch: 642/1000..  Training Loss: 0.004..  Test Loss: 7.403..  Test Accuracy: 0.429\n",
            "Epoch: 643/1000..  Training Loss: 0.004..  Test Loss: 7.395..  Test Accuracy: 0.426\n",
            "Epoch: 644/1000..  Training Loss: 0.004..  Test Loss: 7.479..  Test Accuracy: 0.423\n",
            "Epoch: 645/1000..  Training Loss: 0.005..  Test Loss: 7.473..  Test Accuracy: 0.416\n",
            "Epoch: 646/1000..  Training Loss: 0.004..  Test Loss: 7.482..  Test Accuracy: 0.422\n",
            "Epoch: 647/1000..  Training Loss: 0.004..  Test Loss: 7.432..  Test Accuracy: 0.427\n",
            "Epoch: 648/1000..  Training Loss: 0.004..  Test Loss: 7.398..  Test Accuracy: 0.430\n",
            "Epoch: 649/1000..  Training Loss: 0.004..  Test Loss: 7.462..  Test Accuracy: 0.427\n",
            "Epoch: 650/1000..  Training Loss: 0.004..  Test Loss: 7.514..  Test Accuracy: 0.419\n",
            "Epoch: 651/1000..  Training Loss: 0.004..  Test Loss: 7.468..  Test Accuracy: 0.421\n",
            "Epoch: 652/1000..  Training Loss: 0.004..  Test Loss: 7.444..  Test Accuracy: 0.421\n",
            "Epoch: 653/1000..  Training Loss: 0.004..  Test Loss: 7.472..  Test Accuracy: 0.425\n",
            "Epoch: 654/1000..  Training Loss: 0.004..  Test Loss: 7.472..  Test Accuracy: 0.428\n",
            "Epoch: 655/1000..  Training Loss: 0.005..  Test Loss: 7.479..  Test Accuracy: 0.419\n",
            "Epoch: 656/1000..  Training Loss: 0.004..  Test Loss: 7.421..  Test Accuracy: 0.425\n",
            "Epoch: 657/1000..  Training Loss: 0.004..  Test Loss: 7.492..  Test Accuracy: 0.425\n",
            "Epoch: 658/1000..  Training Loss: 0.004..  Test Loss: 7.500..  Test Accuracy: 0.419\n",
            "Epoch: 659/1000..  Training Loss: 0.004..  Test Loss: 7.494..  Test Accuracy: 0.420\n",
            "Epoch: 660/1000..  Training Loss: 0.004..  Test Loss: 7.481..  Test Accuracy: 0.419\n",
            "Epoch: 661/1000..  Training Loss: 0.004..  Test Loss: 7.395..  Test Accuracy: 0.422\n",
            "Epoch: 662/1000..  Training Loss: 0.004..  Test Loss: 7.452..  Test Accuracy: 0.426\n",
            "Epoch: 663/1000..  Training Loss: 0.004..  Test Loss: 7.431..  Test Accuracy: 0.428\n",
            "Epoch: 664/1000..  Training Loss: 0.004..  Test Loss: 7.472..  Test Accuracy: 0.415\n",
            "Epoch: 665/1000..  Training Loss: 0.004..  Test Loss: 7.430..  Test Accuracy: 0.422\n",
            "Epoch: 666/1000..  Training Loss: 0.004..  Test Loss: 7.473..  Test Accuracy: 0.424\n",
            "Epoch: 667/1000..  Training Loss: 0.004..  Test Loss: 7.448..  Test Accuracy: 0.428\n",
            "Epoch: 668/1000..  Training Loss: 0.004..  Test Loss: 7.452..  Test Accuracy: 0.419\n",
            "Epoch: 669/1000..  Training Loss: 0.004..  Test Loss: 7.481..  Test Accuracy: 0.420\n",
            "Epoch: 670/1000..  Training Loss: 0.004..  Test Loss: 7.475..  Test Accuracy: 0.420\n",
            "Epoch: 671/1000..  Training Loss: 0.004..  Test Loss: 7.372..  Test Accuracy: 0.424\n",
            "Epoch: 672/1000..  Training Loss: 0.004..  Test Loss: 7.421..  Test Accuracy: 0.422\n",
            "Epoch: 673/1000..  Training Loss: 0.004..  Test Loss: 7.499..  Test Accuracy: 0.423\n",
            "Epoch: 674/1000..  Training Loss: 0.004..  Test Loss: 7.477..  Test Accuracy: 0.420\n",
            "Epoch: 675/1000..  Training Loss: 0.004..  Test Loss: 7.448..  Test Accuracy: 0.419\n",
            "Epoch: 676/1000..  Training Loss: 0.005..  Test Loss: 7.461..  Test Accuracy: 0.425\n",
            "Epoch: 677/1000..  Training Loss: 0.004..  Test Loss: 7.450..  Test Accuracy: 0.425\n",
            "Epoch: 678/1000..  Training Loss: 0.004..  Test Loss: 7.463..  Test Accuracy: 0.426\n",
            "Epoch: 679/1000..  Training Loss: 0.004..  Test Loss: 7.528..  Test Accuracy: 0.416\n",
            "Epoch: 680/1000..  Training Loss: 0.004..  Test Loss: 7.473..  Test Accuracy: 0.419\n",
            "Epoch: 681/1000..  Training Loss: 0.004..  Test Loss: 7.477..  Test Accuracy: 0.423\n",
            "Epoch: 682/1000..  Training Loss: 0.004..  Test Loss: 7.474..  Test Accuracy: 0.421\n",
            "Epoch: 683/1000..  Training Loss: 0.004..  Test Loss: 7.459..  Test Accuracy: 0.417\n",
            "Epoch: 684/1000..  Training Loss: 0.004..  Test Loss: 7.486..  Test Accuracy: 0.418\n",
            "Epoch: 685/1000..  Training Loss: 0.004..  Test Loss: 7.443..  Test Accuracy: 0.423\n",
            "Epoch: 686/1000..  Training Loss: 0.004..  Test Loss: 7.495..  Test Accuracy: 0.417\n",
            "Epoch: 687/1000..  Training Loss: 0.004..  Test Loss: 7.469..  Test Accuracy: 0.422\n",
            "Epoch: 688/1000..  Training Loss: 0.004..  Test Loss: 7.419..  Test Accuracy: 0.425\n",
            "Epoch: 689/1000..  Training Loss: 0.004..  Test Loss: 7.501..  Test Accuracy: 0.419\n",
            "Epoch: 690/1000..  Training Loss: 0.004..  Test Loss: 7.536..  Test Accuracy: 0.416\n",
            "Epoch: 691/1000..  Training Loss: 0.004..  Test Loss: 7.500..  Test Accuracy: 0.422\n",
            "Epoch: 692/1000..  Training Loss: 0.004..  Test Loss: 7.490..  Test Accuracy: 0.422\n",
            "Epoch: 693/1000..  Training Loss: 0.004..  Test Loss: 7.477..  Test Accuracy: 0.421\n",
            "Epoch: 694/1000..  Training Loss: 0.004..  Test Loss: 7.519..  Test Accuracy: 0.419\n",
            "Epoch: 695/1000..  Training Loss: 0.004..  Test Loss: 7.443..  Test Accuracy: 0.425\n",
            "Epoch: 696/1000..  Training Loss: 0.004..  Test Loss: 7.580..  Test Accuracy: 0.411\n",
            "Epoch: 697/1000..  Training Loss: 0.004..  Test Loss: 7.548..  Test Accuracy: 0.419\n",
            "Epoch: 698/1000..  Training Loss: 0.004..  Test Loss: 7.543..  Test Accuracy: 0.424\n",
            "Epoch: 699/1000..  Training Loss: 0.005..  Test Loss: 7.481..  Test Accuracy: 0.421\n",
            "Epoch: 700/1000..  Training Loss: 0.005..  Test Loss: 7.496..  Test Accuracy: 0.423\n",
            "Epoch: 701/1000..  Training Loss: 0.004..  Test Loss: 7.488..  Test Accuracy: 0.419\n",
            "Epoch: 702/1000..  Training Loss: 0.004..  Test Loss: 7.535..  Test Accuracy: 0.422\n",
            "Epoch: 703/1000..  Training Loss: 0.004..  Test Loss: 7.501..  Test Accuracy: 0.425\n",
            "Epoch: 704/1000..  Training Loss: 0.004..  Test Loss: 7.497..  Test Accuracy: 0.418\n",
            "Epoch: 705/1000..  Training Loss: 0.004..  Test Loss: 7.519..  Test Accuracy: 0.423\n",
            "Epoch: 706/1000..  Training Loss: 0.004..  Test Loss: 7.497..  Test Accuracy: 0.420\n",
            "Epoch: 707/1000..  Training Loss: 0.004..  Test Loss: 7.480..  Test Accuracy: 0.424\n",
            "Epoch: 708/1000..  Training Loss: 0.004..  Test Loss: 7.532..  Test Accuracy: 0.414\n",
            "Epoch: 709/1000..  Training Loss: 0.004..  Test Loss: 7.523..  Test Accuracy: 0.424\n",
            "Epoch: 710/1000..  Training Loss: 0.004..  Test Loss: 7.380..  Test Accuracy: 0.421\n",
            "Epoch: 711/1000..  Training Loss: 0.004..  Test Loss: 7.538..  Test Accuracy: 0.425\n",
            "Epoch: 712/1000..  Training Loss: 0.005..  Test Loss: 7.544..  Test Accuracy: 0.421\n",
            "Epoch: 713/1000..  Training Loss: 0.004..  Test Loss: 7.514..  Test Accuracy: 0.419\n",
            "Epoch: 714/1000..  Training Loss: 0.004..  Test Loss: 7.538..  Test Accuracy: 0.423\n",
            "Epoch: 715/1000..  Training Loss: 0.004..  Test Loss: 7.604..  Test Accuracy: 0.411\n",
            "Epoch: 716/1000..  Training Loss: 0.004..  Test Loss: 7.543..  Test Accuracy: 0.422\n",
            "Epoch: 717/1000..  Training Loss: 0.005..  Test Loss: 7.500..  Test Accuracy: 0.428\n",
            "Epoch: 718/1000..  Training Loss: 0.004..  Test Loss: 7.487..  Test Accuracy: 0.422\n",
            "Epoch: 719/1000..  Training Loss: 0.005..  Test Loss: 7.640..  Test Accuracy: 0.415\n",
            "Epoch: 720/1000..  Training Loss: 0.004..  Test Loss: 7.603..  Test Accuracy: 0.418\n",
            "Epoch: 721/1000..  Training Loss: 0.004..  Test Loss: 7.612..  Test Accuracy: 0.415\n",
            "Epoch: 722/1000..  Training Loss: 0.004..  Test Loss: 7.509..  Test Accuracy: 0.425\n",
            "Epoch: 723/1000..  Training Loss: 0.004..  Test Loss: 7.501..  Test Accuracy: 0.425\n",
            "Epoch: 724/1000..  Training Loss: 0.004..  Test Loss: 7.533..  Test Accuracy: 0.419\n",
            "Epoch: 725/1000..  Training Loss: 0.004..  Test Loss: 7.624..  Test Accuracy: 0.412\n",
            "Epoch: 726/1000..  Training Loss: 0.005..  Test Loss: 7.510..  Test Accuracy: 0.430\n",
            "Epoch: 727/1000..  Training Loss: 0.005..  Test Loss: 7.505..  Test Accuracy: 0.418\n",
            "Epoch: 728/1000..  Training Loss: 0.004..  Test Loss: 7.518..  Test Accuracy: 0.421\n",
            "Epoch: 729/1000..  Training Loss: 0.004..  Test Loss: 7.561..  Test Accuracy: 0.421\n",
            "Epoch: 730/1000..  Training Loss: 0.004..  Test Loss: 7.602..  Test Accuracy: 0.411\n",
            "Epoch: 731/1000..  Training Loss: 0.004..  Test Loss: 7.478..  Test Accuracy: 0.423\n",
            "Epoch: 732/1000..  Training Loss: 0.004..  Test Loss: 7.522..  Test Accuracy: 0.415\n",
            "Epoch: 733/1000..  Training Loss: 0.005..  Test Loss: 7.654..  Test Accuracy: 0.413\n",
            "Epoch: 734/1000..  Training Loss: 0.004..  Test Loss: 7.662..  Test Accuracy: 0.411\n",
            "Epoch: 735/1000..  Training Loss: 0.004..  Test Loss: 7.613..  Test Accuracy: 0.415\n",
            "Epoch: 736/1000..  Training Loss: 0.004..  Test Loss: 7.592..  Test Accuracy: 0.424\n",
            "Epoch: 737/1000..  Training Loss: 0.004..  Test Loss: 7.575..  Test Accuracy: 0.415\n",
            "Epoch: 738/1000..  Training Loss: 0.004..  Test Loss: 7.453..  Test Accuracy: 0.422\n",
            "Epoch: 739/1000..  Training Loss: 0.004..  Test Loss: 7.523..  Test Accuracy: 0.415\n",
            "Epoch: 740/1000..  Training Loss: 0.004..  Test Loss: 7.520..  Test Accuracy: 0.421\n",
            "Epoch: 741/1000..  Training Loss: 0.004..  Test Loss: 7.660..  Test Accuracy: 0.420\n",
            "Epoch: 742/1000..  Training Loss: 0.004..  Test Loss: 7.555..  Test Accuracy: 0.424\n",
            "Epoch: 743/1000..  Training Loss: 0.004..  Test Loss: 7.562..  Test Accuracy: 0.416\n",
            "Epoch: 744/1000..  Training Loss: 0.004..  Test Loss: 7.599..  Test Accuracy: 0.419\n",
            "Epoch: 745/1000..  Training Loss: 0.004..  Test Loss: 7.526..  Test Accuracy: 0.412\n",
            "Epoch: 746/1000..  Training Loss: 0.004..  Test Loss: 7.541..  Test Accuracy: 0.425\n",
            "Epoch: 747/1000..  Training Loss: 0.004..  Test Loss: 7.580..  Test Accuracy: 0.420\n",
            "Epoch: 748/1000..  Training Loss: 0.005..  Test Loss: 7.559..  Test Accuracy: 0.420\n",
            "Epoch: 749/1000..  Training Loss: 0.005..  Test Loss: 7.539..  Test Accuracy: 0.425\n",
            "Epoch: 750/1000..  Training Loss: 0.005..  Test Loss: 7.596..  Test Accuracy: 0.416\n",
            "Epoch: 751/1000..  Training Loss: 0.004..  Test Loss: 7.680..  Test Accuracy: 0.424\n",
            "Epoch: 752/1000..  Training Loss: 0.004..  Test Loss: 7.583..  Test Accuracy: 0.412\n",
            "Epoch: 753/1000..  Training Loss: 0.004..  Test Loss: 7.514..  Test Accuracy: 0.419\n",
            "Epoch: 754/1000..  Training Loss: 0.004..  Test Loss: 7.603..  Test Accuracy: 0.416\n",
            "Epoch: 755/1000..  Training Loss: 0.005..  Test Loss: 7.595..  Test Accuracy: 0.419\n",
            "Epoch: 756/1000..  Training Loss: 0.004..  Test Loss: 7.578..  Test Accuracy: 0.419\n",
            "Epoch: 757/1000..  Training Loss: 0.004..  Test Loss: 7.565..  Test Accuracy: 0.430\n",
            "Epoch: 758/1000..  Training Loss: 0.004..  Test Loss: 7.607..  Test Accuracy: 0.418\n",
            "Epoch: 759/1000..  Training Loss: 0.004..  Test Loss: 7.581..  Test Accuracy: 0.419\n",
            "Epoch: 760/1000..  Training Loss: 0.004..  Test Loss: 7.581..  Test Accuracy: 0.415\n",
            "Epoch: 761/1000..  Training Loss: 0.004..  Test Loss: 7.545..  Test Accuracy: 0.421\n",
            "Epoch: 762/1000..  Training Loss: 0.004..  Test Loss: 7.615..  Test Accuracy: 0.421\n",
            "Epoch: 763/1000..  Training Loss: 0.004..  Test Loss: 7.559..  Test Accuracy: 0.425\n",
            "Epoch: 764/1000..  Training Loss: 0.004..  Test Loss: 7.661..  Test Accuracy: 0.408\n",
            "Epoch: 765/1000..  Training Loss: 0.004..  Test Loss: 7.505..  Test Accuracy: 0.420\n",
            "Epoch: 766/1000..  Training Loss: 0.004..  Test Loss: 7.602..  Test Accuracy: 0.413\n",
            "Epoch: 767/1000..  Training Loss: 0.004..  Test Loss: 7.550..  Test Accuracy: 0.421\n",
            "Epoch: 768/1000..  Training Loss: 0.004..  Test Loss: 7.511..  Test Accuracy: 0.425\n",
            "Epoch: 769/1000..  Training Loss: 0.004..  Test Loss: 7.661..  Test Accuracy: 0.412\n",
            "Epoch: 770/1000..  Training Loss: 0.004..  Test Loss: 7.603..  Test Accuracy: 0.414\n",
            "Epoch: 771/1000..  Training Loss: 0.004..  Test Loss: 7.614..  Test Accuracy: 0.416\n",
            "Epoch: 772/1000..  Training Loss: 0.004..  Test Loss: 7.684..  Test Accuracy: 0.419\n",
            "Epoch: 773/1000..  Training Loss: 0.004..  Test Loss: 7.683..  Test Accuracy: 0.415\n",
            "Epoch: 774/1000..  Training Loss: 0.004..  Test Loss: 7.664..  Test Accuracy: 0.419\n",
            "Epoch: 775/1000..  Training Loss: 0.004..  Test Loss: 7.571..  Test Accuracy: 0.417\n",
            "Epoch: 776/1000..  Training Loss: 0.004..  Test Loss: 7.644..  Test Accuracy: 0.422\n",
            "Epoch: 777/1000..  Training Loss: 0.004..  Test Loss: 7.651..  Test Accuracy: 0.416\n",
            "Epoch: 778/1000..  Training Loss: 0.004..  Test Loss: 7.632..  Test Accuracy: 0.415\n",
            "Epoch: 779/1000..  Training Loss: 0.004..  Test Loss: 7.603..  Test Accuracy: 0.407\n",
            "Epoch: 780/1000..  Training Loss: 0.004..  Test Loss: 7.607..  Test Accuracy: 0.421\n",
            "Epoch: 781/1000..  Training Loss: 0.004..  Test Loss: 7.608..  Test Accuracy: 0.422\n",
            "Epoch: 782/1000..  Training Loss: 0.004..  Test Loss: 7.575..  Test Accuracy: 0.421\n",
            "Epoch: 783/1000..  Training Loss: 0.004..  Test Loss: 7.657..  Test Accuracy: 0.421\n",
            "Epoch: 784/1000..  Training Loss: 0.004..  Test Loss: 7.673..  Test Accuracy: 0.421\n",
            "Epoch: 785/1000..  Training Loss: 0.004..  Test Loss: 7.647..  Test Accuracy: 0.419\n",
            "Epoch: 786/1000..  Training Loss: 0.004..  Test Loss: 7.704..  Test Accuracy: 0.420\n",
            "Epoch: 787/1000..  Training Loss: 0.004..  Test Loss: 7.632..  Test Accuracy: 0.415\n",
            "Epoch: 788/1000..  Training Loss: 0.004..  Test Loss: 7.756..  Test Accuracy: 0.415\n",
            "Epoch: 789/1000..  Training Loss: 0.004..  Test Loss: 7.571..  Test Accuracy: 0.421\n",
            "Epoch: 790/1000..  Training Loss: 0.004..  Test Loss: 7.708..  Test Accuracy: 0.423\n",
            "Epoch: 791/1000..  Training Loss: 0.004..  Test Loss: 7.657..  Test Accuracy: 0.418\n",
            "Epoch: 792/1000..  Training Loss: 0.004..  Test Loss: 7.573..  Test Accuracy: 0.420\n",
            "Epoch: 793/1000..  Training Loss: 0.004..  Test Loss: 7.611..  Test Accuracy: 0.423\n",
            "Epoch: 794/1000..  Training Loss: 0.004..  Test Loss: 7.605..  Test Accuracy: 0.416\n",
            "Epoch: 795/1000..  Training Loss: 0.004..  Test Loss: 7.710..  Test Accuracy: 0.416\n",
            "Epoch: 796/1000..  Training Loss: 0.004..  Test Loss: 7.647..  Test Accuracy: 0.421\n",
            "Epoch: 797/1000..  Training Loss: 0.005..  Test Loss: 7.796..  Test Accuracy: 0.409\n",
            "Epoch: 798/1000..  Training Loss: 0.004..  Test Loss: 7.677..  Test Accuracy: 0.420\n",
            "Epoch: 799/1000..  Training Loss: 0.004..  Test Loss: 7.736..  Test Accuracy: 0.417\n",
            "Epoch: 800/1000..  Training Loss: 0.004..  Test Loss: 7.736..  Test Accuracy: 0.411\n",
            "Epoch: 801/1000..  Training Loss: 0.004..  Test Loss: 7.791..  Test Accuracy: 0.414\n",
            "Epoch: 802/1000..  Training Loss: 0.004..  Test Loss: 7.758..  Test Accuracy: 0.415\n",
            "Epoch: 803/1000..  Training Loss: 0.004..  Test Loss: 7.678..  Test Accuracy: 0.425\n",
            "Epoch: 804/1000..  Training Loss: 0.004..  Test Loss: 7.651..  Test Accuracy: 0.420\n",
            "Epoch: 805/1000..  Training Loss: 0.004..  Test Loss: 7.676..  Test Accuracy: 0.423\n",
            "Epoch: 806/1000..  Training Loss: 0.004..  Test Loss: 7.670..  Test Accuracy: 0.414\n",
            "Epoch: 807/1000..  Training Loss: 0.004..  Test Loss: 7.658..  Test Accuracy: 0.411\n",
            "Epoch: 808/1000..  Training Loss: 0.004..  Test Loss: 7.676..  Test Accuracy: 0.415\n",
            "Epoch: 809/1000..  Training Loss: 0.004..  Test Loss: 7.700..  Test Accuracy: 0.422\n",
            "Epoch: 810/1000..  Training Loss: 0.004..  Test Loss: 7.647..  Test Accuracy: 0.419\n",
            "Epoch: 811/1000..  Training Loss: 0.004..  Test Loss: 7.654..  Test Accuracy: 0.415\n",
            "Epoch: 812/1000..  Training Loss: 0.004..  Test Loss: 7.662..  Test Accuracy: 0.412\n",
            "Epoch: 813/1000..  Training Loss: 0.004..  Test Loss: 7.713..  Test Accuracy: 0.411\n",
            "Epoch: 814/1000..  Training Loss: 0.004..  Test Loss: 7.760..  Test Accuracy: 0.414\n",
            "Epoch: 815/1000..  Training Loss: 0.004..  Test Loss: 7.588..  Test Accuracy: 0.418\n",
            "Epoch: 816/1000..  Training Loss: 0.004..  Test Loss: 7.715..  Test Accuracy: 0.421\n",
            "Epoch: 817/1000..  Training Loss: 0.004..  Test Loss: 7.764..  Test Accuracy: 0.422\n",
            "Epoch: 818/1000..  Training Loss: 0.004..  Test Loss: 7.664..  Test Accuracy: 0.415\n",
            "Epoch: 819/1000..  Training Loss: 0.004..  Test Loss: 7.640..  Test Accuracy: 0.416\n",
            "Epoch: 820/1000..  Training Loss: 0.004..  Test Loss: 7.706..  Test Accuracy: 0.421\n",
            "Epoch: 821/1000..  Training Loss: 0.004..  Test Loss: 7.855..  Test Accuracy: 0.415\n",
            "Epoch: 822/1000..  Training Loss: 0.004..  Test Loss: 7.782..  Test Accuracy: 0.424\n",
            "Epoch: 823/1000..  Training Loss: 0.004..  Test Loss: 7.730..  Test Accuracy: 0.414\n",
            "Epoch: 824/1000..  Training Loss: 0.004..  Test Loss: 7.690..  Test Accuracy: 0.413\n",
            "Epoch: 825/1000..  Training Loss: 0.004..  Test Loss: 7.774..  Test Accuracy: 0.423\n",
            "Epoch: 826/1000..  Training Loss: 0.004..  Test Loss: 7.881..  Test Accuracy: 0.413\n",
            "Epoch: 827/1000..  Training Loss: 0.004..  Test Loss: 7.691..  Test Accuracy: 0.421\n",
            "Epoch: 828/1000..  Training Loss: 0.004..  Test Loss: 7.660..  Test Accuracy: 0.412\n",
            "Epoch: 829/1000..  Training Loss: 0.004..  Test Loss: 7.788..  Test Accuracy: 0.418\n",
            "Epoch: 830/1000..  Training Loss: 0.004..  Test Loss: 7.739..  Test Accuracy: 0.413\n",
            "Epoch: 831/1000..  Training Loss: 0.004..  Test Loss: 7.852..  Test Accuracy: 0.416\n",
            "Epoch: 832/1000..  Training Loss: 0.004..  Test Loss: 7.803..  Test Accuracy: 0.413\n",
            "Epoch: 833/1000..  Training Loss: 0.004..  Test Loss: 7.682..  Test Accuracy: 0.417\n",
            "Epoch: 834/1000..  Training Loss: 0.004..  Test Loss: 7.735..  Test Accuracy: 0.418\n",
            "Epoch: 835/1000..  Training Loss: 0.004..  Test Loss: 7.666..  Test Accuracy: 0.415\n",
            "Epoch: 836/1000..  Training Loss: 0.004..  Test Loss: 7.796..  Test Accuracy: 0.407\n",
            "Epoch: 837/1000..  Training Loss: 0.004..  Test Loss: 7.770..  Test Accuracy: 0.419\n",
            "Epoch: 838/1000..  Training Loss: 0.004..  Test Loss: 7.775..  Test Accuracy: 0.415\n",
            "Epoch: 839/1000..  Training Loss: 0.004..  Test Loss: 7.787..  Test Accuracy: 0.416\n",
            "Epoch: 840/1000..  Training Loss: 0.004..  Test Loss: 7.692..  Test Accuracy: 0.421\n",
            "Epoch: 841/1000..  Training Loss: 0.004..  Test Loss: 7.755..  Test Accuracy: 0.416\n",
            "Epoch: 842/1000..  Training Loss: 0.004..  Test Loss: 7.870..  Test Accuracy: 0.415\n",
            "Epoch: 843/1000..  Training Loss: 0.004..  Test Loss: 7.687..  Test Accuracy: 0.413\n",
            "Epoch: 844/1000..  Training Loss: 0.004..  Test Loss: 7.825..  Test Accuracy: 0.416\n",
            "Epoch: 845/1000..  Training Loss: 0.004..  Test Loss: 7.696..  Test Accuracy: 0.408\n",
            "Epoch: 846/1000..  Training Loss: 0.004..  Test Loss: 7.873..  Test Accuracy: 0.411\n",
            "Epoch: 847/1000..  Training Loss: 0.004..  Test Loss: 7.795..  Test Accuracy: 0.416\n",
            "Epoch: 848/1000..  Training Loss: 0.004..  Test Loss: 7.895..  Test Accuracy: 0.410\n",
            "Epoch: 849/1000..  Training Loss: 0.004..  Test Loss: 7.796..  Test Accuracy: 0.417\n",
            "Epoch: 850/1000..  Training Loss: 0.004..  Test Loss: 7.908..  Test Accuracy: 0.421\n",
            "Epoch: 851/1000..  Training Loss: 0.004..  Test Loss: 7.687..  Test Accuracy: 0.407\n",
            "Epoch: 852/1000..  Training Loss: 0.004..  Test Loss: 7.778..  Test Accuracy: 0.429\n",
            "Epoch: 853/1000..  Training Loss: 0.004..  Test Loss: 7.753..  Test Accuracy: 0.429\n",
            "Epoch: 854/1000..  Training Loss: 0.004..  Test Loss: 7.807..  Test Accuracy: 0.413\n",
            "Epoch: 855/1000..  Training Loss: 0.004..  Test Loss: 7.958..  Test Accuracy: 0.418\n",
            "Epoch: 856/1000..  Training Loss: 0.004..  Test Loss: 7.865..  Test Accuracy: 0.416\n",
            "Epoch: 857/1000..  Training Loss: 0.004..  Test Loss: 7.866..  Test Accuracy: 0.429\n",
            "Epoch: 858/1000..  Training Loss: 0.004..  Test Loss: 7.840..  Test Accuracy: 0.416\n",
            "Epoch: 859/1000..  Training Loss: 0.004..  Test Loss: 7.852..  Test Accuracy: 0.423\n",
            "Epoch: 860/1000..  Training Loss: 0.004..  Test Loss: 7.859..  Test Accuracy: 0.423\n",
            "Epoch: 861/1000..  Training Loss: 0.004..  Test Loss: 7.697..  Test Accuracy: 0.421\n",
            "Epoch: 862/1000..  Training Loss: 0.004..  Test Loss: 7.683..  Test Accuracy: 0.418\n",
            "Epoch: 863/1000..  Training Loss: 0.004..  Test Loss: 7.753..  Test Accuracy: 0.413\n",
            "Epoch: 864/1000..  Training Loss: 0.004..  Test Loss: 7.851..  Test Accuracy: 0.424\n",
            "Epoch: 865/1000..  Training Loss: 0.004..  Test Loss: 7.881..  Test Accuracy: 0.424\n",
            "Epoch: 866/1000..  Training Loss: 0.004..  Test Loss: 7.792..  Test Accuracy: 0.414\n",
            "Epoch: 867/1000..  Training Loss: 0.004..  Test Loss: 7.787..  Test Accuracy: 0.422\n",
            "Epoch: 868/1000..  Training Loss: 0.004..  Test Loss: 7.821..  Test Accuracy: 0.406\n",
            "Epoch: 869/1000..  Training Loss: 0.004..  Test Loss: 7.832..  Test Accuracy: 0.425\n",
            "Epoch: 870/1000..  Training Loss: 0.004..  Test Loss: 7.788..  Test Accuracy: 0.424\n",
            "Epoch: 871/1000..  Training Loss: 0.004..  Test Loss: 7.802..  Test Accuracy: 0.424\n",
            "Epoch: 872/1000..  Training Loss: 0.004..  Test Loss: 7.936..  Test Accuracy: 0.414\n",
            "Epoch: 873/1000..  Training Loss: 0.004..  Test Loss: 7.847..  Test Accuracy: 0.407\n",
            "Epoch: 874/1000..  Training Loss: 0.004..  Test Loss: 7.926..  Test Accuracy: 0.412\n",
            "Epoch: 875/1000..  Training Loss: 0.004..  Test Loss: 7.791..  Test Accuracy: 0.407\n",
            "Epoch: 876/1000..  Training Loss: 0.004..  Test Loss: 7.990..  Test Accuracy: 0.412\n",
            "Epoch: 877/1000..  Training Loss: 0.004..  Test Loss: 7.946..  Test Accuracy: 0.419\n",
            "Epoch: 878/1000..  Training Loss: 0.004..  Test Loss: 7.809..  Test Accuracy: 0.427\n",
            "Epoch: 879/1000..  Training Loss: 0.004..  Test Loss: 7.899..  Test Accuracy: 0.425\n",
            "Epoch: 880/1000..  Training Loss: 0.004..  Test Loss: 7.939..  Test Accuracy: 0.416\n",
            "Epoch: 881/1000..  Training Loss: 0.004..  Test Loss: 8.033..  Test Accuracy: 0.410\n",
            "Epoch: 882/1000..  Training Loss: 0.004..  Test Loss: 8.079..  Test Accuracy: 0.419\n",
            "Epoch: 883/1000..  Training Loss: 0.004..  Test Loss: 7.972..  Test Accuracy: 0.417\n",
            "Epoch: 884/1000..  Training Loss: 0.004..  Test Loss: 8.128..  Test Accuracy: 0.409\n",
            "Epoch: 885/1000..  Training Loss: 0.004..  Test Loss: 7.959..  Test Accuracy: 0.409\n",
            "Epoch: 886/1000..  Training Loss: 0.004..  Test Loss: 8.060..  Test Accuracy: 0.414\n",
            "Epoch: 887/1000..  Training Loss: 0.004..  Test Loss: 7.940..  Test Accuracy: 0.404\n",
            "Epoch: 888/1000..  Training Loss: 0.004..  Test Loss: 7.830..  Test Accuracy: 0.419\n",
            "Epoch: 889/1000..  Training Loss: 0.004..  Test Loss: 7.886..  Test Accuracy: 0.420\n",
            "Epoch: 890/1000..  Training Loss: 0.004..  Test Loss: 7.943..  Test Accuracy: 0.430\n",
            "Epoch: 891/1000..  Training Loss: 0.004..  Test Loss: 7.911..  Test Accuracy: 0.412\n",
            "Epoch: 892/1000..  Training Loss: 0.004..  Test Loss: 8.062..  Test Accuracy: 0.413\n",
            "Epoch: 893/1000..  Training Loss: 0.004..  Test Loss: 8.117..  Test Accuracy: 0.407\n",
            "Epoch: 894/1000..  Training Loss: 0.004..  Test Loss: 7.925..  Test Accuracy: 0.412\n",
            "Epoch: 895/1000..  Training Loss: 0.004..  Test Loss: 8.011..  Test Accuracy: 0.421\n",
            "Epoch: 896/1000..  Training Loss: 0.004..  Test Loss: 8.003..  Test Accuracy: 0.407\n",
            "Epoch: 897/1000..  Training Loss: 0.004..  Test Loss: 7.943..  Test Accuracy: 0.412\n",
            "Epoch: 898/1000..  Training Loss: 0.004..  Test Loss: 7.923..  Test Accuracy: 0.412\n",
            "Epoch: 899/1000..  Training Loss: 0.004..  Test Loss: 7.992..  Test Accuracy: 0.420\n",
            "Epoch: 900/1000..  Training Loss: 0.004..  Test Loss: 8.065..  Test Accuracy: 0.411\n",
            "Epoch: 901/1000..  Training Loss: 0.132..  Test Loss: 9.243..  Test Accuracy: 0.397\n",
            "Epoch: 902/1000..  Training Loss: 0.307..  Test Loss: 8.248..  Test Accuracy: 0.436\n",
            "Epoch: 903/1000..  Training Loss: 0.034..  Test Loss: 8.027..  Test Accuracy: 0.397\n",
            "Epoch: 904/1000..  Training Loss: 0.014..  Test Loss: 8.408..  Test Accuracy: 0.403\n",
            "Epoch: 905/1000..  Training Loss: 0.005..  Test Loss: 8.131..  Test Accuracy: 0.397\n",
            "Epoch: 906/1000..  Training Loss: 0.004..  Test Loss: 7.983..  Test Accuracy: 0.401\n",
            "Epoch: 907/1000..  Training Loss: 0.004..  Test Loss: 8.087..  Test Accuracy: 0.406\n",
            "Epoch: 908/1000..  Training Loss: 0.004..  Test Loss: 8.059..  Test Accuracy: 0.403\n",
            "Epoch: 909/1000..  Training Loss: 0.004..  Test Loss: 8.018..  Test Accuracy: 0.405\n",
            "Epoch: 910/1000..  Training Loss: 0.004..  Test Loss: 8.014..  Test Accuracy: 0.405\n",
            "Epoch: 911/1000..  Training Loss: 0.004..  Test Loss: 8.055..  Test Accuracy: 0.406\n",
            "Epoch: 912/1000..  Training Loss: 0.004..  Test Loss: 8.034..  Test Accuracy: 0.403\n",
            "Epoch: 913/1000..  Training Loss: 0.004..  Test Loss: 8.025..  Test Accuracy: 0.406\n",
            "Epoch: 914/1000..  Training Loss: 0.004..  Test Loss: 8.071..  Test Accuracy: 0.403\n",
            "Epoch: 915/1000..  Training Loss: 0.004..  Test Loss: 8.018..  Test Accuracy: 0.409\n",
            "Epoch: 916/1000..  Training Loss: 0.004..  Test Loss: 8.013..  Test Accuracy: 0.408\n",
            "Epoch: 917/1000..  Training Loss: 0.004..  Test Loss: 8.027..  Test Accuracy: 0.405\n",
            "Epoch: 918/1000..  Training Loss: 0.004..  Test Loss: 7.991..  Test Accuracy: 0.406\n",
            "Epoch: 919/1000..  Training Loss: 0.004..  Test Loss: 7.990..  Test Accuracy: 0.410\n",
            "Epoch: 920/1000..  Training Loss: 0.004..  Test Loss: 8.067..  Test Accuracy: 0.405\n",
            "Epoch: 921/1000..  Training Loss: 0.004..  Test Loss: 8.056..  Test Accuracy: 0.406\n",
            "Epoch: 922/1000..  Training Loss: 0.004..  Test Loss: 8.033..  Test Accuracy: 0.408\n",
            "Epoch: 923/1000..  Training Loss: 0.004..  Test Loss: 8.073..  Test Accuracy: 0.405\n",
            "Epoch: 924/1000..  Training Loss: 0.004..  Test Loss: 8.039..  Test Accuracy: 0.409\n",
            "Epoch: 925/1000..  Training Loss: 0.004..  Test Loss: 8.076..  Test Accuracy: 0.407\n",
            "Epoch: 926/1000..  Training Loss: 0.004..  Test Loss: 8.035..  Test Accuracy: 0.408\n",
            "Epoch: 927/1000..  Training Loss: 0.004..  Test Loss: 7.987..  Test Accuracy: 0.407\n",
            "Epoch: 928/1000..  Training Loss: 0.004..  Test Loss: 7.955..  Test Accuracy: 0.411\n",
            "Epoch: 929/1000..  Training Loss: 0.004..  Test Loss: 8.068..  Test Accuracy: 0.403\n",
            "Epoch: 930/1000..  Training Loss: 0.004..  Test Loss: 8.026..  Test Accuracy: 0.409\n",
            "Epoch: 931/1000..  Training Loss: 0.004..  Test Loss: 8.045..  Test Accuracy: 0.408\n",
            "Epoch: 932/1000..  Training Loss: 0.004..  Test Loss: 8.027..  Test Accuracy: 0.408\n",
            "Epoch: 933/1000..  Training Loss: 0.004..  Test Loss: 8.068..  Test Accuracy: 0.408\n",
            "Epoch: 934/1000..  Training Loss: 0.004..  Test Loss: 8.029..  Test Accuracy: 0.407\n",
            "Epoch: 935/1000..  Training Loss: 0.004..  Test Loss: 8.002..  Test Accuracy: 0.410\n",
            "Epoch: 936/1000..  Training Loss: 0.004..  Test Loss: 8.017..  Test Accuracy: 0.410\n",
            "Epoch: 937/1000..  Training Loss: 0.004..  Test Loss: 8.067..  Test Accuracy: 0.403\n",
            "Epoch: 938/1000..  Training Loss: 0.004..  Test Loss: 8.040..  Test Accuracy: 0.408\n",
            "Epoch: 939/1000..  Training Loss: 0.004..  Test Loss: 7.998..  Test Accuracy: 0.408\n",
            "Epoch: 940/1000..  Training Loss: 0.004..  Test Loss: 8.039..  Test Accuracy: 0.407\n",
            "Epoch: 941/1000..  Training Loss: 0.004..  Test Loss: 8.106..  Test Accuracy: 0.404\n",
            "Epoch: 942/1000..  Training Loss: 0.004..  Test Loss: 8.079..  Test Accuracy: 0.403\n",
            "Epoch: 943/1000..  Training Loss: 0.004..  Test Loss: 7.979..  Test Accuracy: 0.410\n",
            "Epoch: 944/1000..  Training Loss: 0.004..  Test Loss: 8.063..  Test Accuracy: 0.408\n",
            "Epoch: 945/1000..  Training Loss: 0.004..  Test Loss: 8.097..  Test Accuracy: 0.410\n",
            "Epoch: 946/1000..  Training Loss: 0.003..  Test Loss: 8.053..  Test Accuracy: 0.408\n",
            "Epoch: 947/1000..  Training Loss: 0.004..  Test Loss: 8.092..  Test Accuracy: 0.407\n",
            "Epoch: 948/1000..  Training Loss: 0.004..  Test Loss: 8.062..  Test Accuracy: 0.409\n",
            "Epoch: 949/1000..  Training Loss: 0.004..  Test Loss: 8.100..  Test Accuracy: 0.402\n",
            "Epoch: 950/1000..  Training Loss: 0.004..  Test Loss: 7.988..  Test Accuracy: 0.410\n",
            "Epoch: 951/1000..  Training Loss: 0.004..  Test Loss: 8.022..  Test Accuracy: 0.412\n",
            "Epoch: 952/1000..  Training Loss: 0.004..  Test Loss: 8.006..  Test Accuracy: 0.409\n",
            "Epoch: 953/1000..  Training Loss: 0.004..  Test Loss: 8.030..  Test Accuracy: 0.412\n",
            "Epoch: 954/1000..  Training Loss: 0.003..  Test Loss: 8.063..  Test Accuracy: 0.407\n",
            "Epoch: 955/1000..  Training Loss: 0.004..  Test Loss: 8.068..  Test Accuracy: 0.407\n",
            "Epoch: 956/1000..  Training Loss: 0.004..  Test Loss: 8.061..  Test Accuracy: 0.410\n",
            "Epoch: 957/1000..  Training Loss: 0.004..  Test Loss: 8.082..  Test Accuracy: 0.411\n",
            "Epoch: 958/1000..  Training Loss: 0.004..  Test Loss: 8.039..  Test Accuracy: 0.413\n",
            "Epoch: 959/1000..  Training Loss: 0.004..  Test Loss: 8.053..  Test Accuracy: 0.407\n",
            "Epoch: 960/1000..  Training Loss: 0.004..  Test Loss: 8.077..  Test Accuracy: 0.405\n",
            "Epoch: 961/1000..  Training Loss: 0.004..  Test Loss: 8.055..  Test Accuracy: 0.409\n",
            "Epoch: 962/1000..  Training Loss: 0.004..  Test Loss: 8.089..  Test Accuracy: 0.410\n",
            "Epoch: 963/1000..  Training Loss: 0.004..  Test Loss: 8.087..  Test Accuracy: 0.407\n",
            "Epoch: 964/1000..  Training Loss: 0.004..  Test Loss: 8.059..  Test Accuracy: 0.409\n",
            "Epoch: 965/1000..  Training Loss: 0.003..  Test Loss: 8.057..  Test Accuracy: 0.413\n",
            "Epoch: 966/1000..  Training Loss: 0.004..  Test Loss: 8.024..  Test Accuracy: 0.413\n",
            "Epoch: 967/1000..  Training Loss: 0.003..  Test Loss: 8.060..  Test Accuracy: 0.411\n",
            "Epoch: 968/1000..  Training Loss: 0.004..  Test Loss: 8.058..  Test Accuracy: 0.412\n",
            "Epoch: 969/1000..  Training Loss: 0.004..  Test Loss: 8.051..  Test Accuracy: 0.408\n",
            "Epoch: 970/1000..  Training Loss: 0.004..  Test Loss: 8.042..  Test Accuracy: 0.412\n",
            "Epoch: 971/1000..  Training Loss: 0.004..  Test Loss: 8.067..  Test Accuracy: 0.412\n",
            "Epoch: 972/1000..  Training Loss: 0.004..  Test Loss: 8.075..  Test Accuracy: 0.412\n",
            "Epoch: 973/1000..  Training Loss: 0.004..  Test Loss: 8.087..  Test Accuracy: 0.411\n",
            "Epoch: 974/1000..  Training Loss: 0.004..  Test Loss: 8.055..  Test Accuracy: 0.412\n",
            "Epoch: 975/1000..  Training Loss: 0.004..  Test Loss: 8.079..  Test Accuracy: 0.407\n",
            "Epoch: 976/1000..  Training Loss: 0.004..  Test Loss: 8.081..  Test Accuracy: 0.413\n",
            "Epoch: 977/1000..  Training Loss: 0.004..  Test Loss: 8.106..  Test Accuracy: 0.405\n",
            "Epoch: 978/1000..  Training Loss: 0.003..  Test Loss: 8.091..  Test Accuracy: 0.413\n",
            "Epoch: 979/1000..  Training Loss: 0.004..  Test Loss: 8.075..  Test Accuracy: 0.412\n",
            "Epoch: 980/1000..  Training Loss: 0.003..  Test Loss: 8.063..  Test Accuracy: 0.412\n",
            "Epoch: 981/1000..  Training Loss: 0.004..  Test Loss: 8.087..  Test Accuracy: 0.410\n",
            "Epoch: 982/1000..  Training Loss: 0.004..  Test Loss: 8.083..  Test Accuracy: 0.410\n",
            "Epoch: 983/1000..  Training Loss: 0.004..  Test Loss: 8.091..  Test Accuracy: 0.412\n",
            "Epoch: 984/1000..  Training Loss: 0.004..  Test Loss: 8.076..  Test Accuracy: 0.411\n",
            "Epoch: 985/1000..  Training Loss: 0.004..  Test Loss: 8.050..  Test Accuracy: 0.412\n",
            "Epoch: 986/1000..  Training Loss: 0.004..  Test Loss: 8.090..  Test Accuracy: 0.412\n",
            "Epoch: 987/1000..  Training Loss: 0.003..  Test Loss: 8.124..  Test Accuracy: 0.411\n",
            "Epoch: 988/1000..  Training Loss: 0.004..  Test Loss: 8.088..  Test Accuracy: 0.413\n",
            "Epoch: 989/1000..  Training Loss: 0.004..  Test Loss: 8.138..  Test Accuracy: 0.407\n",
            "Epoch: 990/1000..  Training Loss: 0.004..  Test Loss: 8.143..  Test Accuracy: 0.407\n",
            "Epoch: 991/1000..  Training Loss: 0.003..  Test Loss: 8.104..  Test Accuracy: 0.411\n",
            "Epoch: 992/1000..  Training Loss: 0.003..  Test Loss: 8.088..  Test Accuracy: 0.414\n",
            "Epoch: 993/1000..  Training Loss: 0.004..  Test Loss: 8.091..  Test Accuracy: 0.413\n",
            "Epoch: 994/1000..  Training Loss: 0.004..  Test Loss: 8.064..  Test Accuracy: 0.416\n",
            "Epoch: 995/1000..  Training Loss: 0.004..  Test Loss: 8.079..  Test Accuracy: 0.412\n",
            "Epoch: 996/1000..  Training Loss: 0.004..  Test Loss: 8.058..  Test Accuracy: 0.415\n",
            "Epoch: 997/1000..  Training Loss: 0.004..  Test Loss: 8.112..  Test Accuracy: 0.412\n",
            "Epoch: 998/1000..  Training Loss: 0.004..  Test Loss: 8.125..  Test Accuracy: 0.412\n",
            "Epoch: 999/1000..  Training Loss: 0.004..  Test Loss: 8.145..  Test Accuracy: 0.411\n",
            "Epoch: 1000/1000..  Training Loss: 0.004..  Test Loss: 8.119..  Test Accuracy: 0.414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rngJFiOnrlbn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "fa40ec39-78a6-4a39-d652-ebe5835323f5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(test_losses, label='Validation loss')\n",
        "plt.legend(frameon=False)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f1290d17f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}